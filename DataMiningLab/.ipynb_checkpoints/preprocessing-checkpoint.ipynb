{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTree.py init\n",
      "columns {'uid': 'uid', 'tran_time': 'sldatime', 'gender_age': 'cmrid', 'vipno': 'vipno', 'itemno': 'pluno', 'amount': 'amt', 'quantity': 'qty', 'brandno': 'bndno', 'class1': 'class1', 'class2': 'class2', 'class3': 'class3', 'class4': 'class4', 'class5': 'class5'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import *\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neighbors import *\n",
    "from collections import *\n",
    "from pyclust import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.cluster import KMeans\n",
    "from module.EKmeans import *\n",
    "from module.CTree import *\n",
    "import datetime\n",
    "from collections import *\n",
    "import copy\n",
    "\n",
    "DATA_PATH = './trade_new.csv'\n",
    "\n",
    "_col = {\n",
    "    'uid':'uid',\n",
    "    'tran_time':'sldatime', #\n",
    "    'gender_age':'cmrid',\n",
    "    'vipno':'vipno', #\n",
    "    'itemno':'pluno', #\n",
    "    'amount':'amt', #\n",
    "    'quantity':'qty', #\n",
    "    'brandno':'bndno', #\n",
    "}\n",
    "\n",
    "_col_class = {\n",
    "    'class1':'class1',\n",
    "    'class2':'class2',\n",
    "    'class3':'class3',\n",
    "    'class4':'class4',\n",
    "    'class5':'class5',\n",
    "}\n",
    "\n",
    "_col2 ={**_col,**_col_class}\n",
    "\n",
    "print('columns',_col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[_col.values()]\n",
    "new_df = pd.DataFrame([],columns=_col2.values())\n",
    "\n",
    "\n",
    "category = df[_col2['itemno']].values.astype('str')\n",
    "category = np.array(list(map(lambda x:np.array([x[:2],x[:3],x[:4],x[:5],x[5:]]),category)))\n",
    "category = pd.DataFrame(category,columns=_col_class.values())\n",
    "if (category.index.start == df.index.start) and \\\n",
    "    (category.index.stop == df.index.stop):\n",
    "    new_df = df.join(category)\n",
    "\n",
    "df_amount_sum = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2'],_col2['class3'],_col2['class4']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum3 = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2'],_col2['class3']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum2 = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum1 = new_df.groupby([_col2['vipno'],_col2['class1']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount = [df_amount_sum1, df_amount_sum2, df_amount_sum3, df_amount_sum]\n",
    "del df\n",
    "# df_amount_sum.to_csv('./result/a1-amount_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_vipno = set(df_amount_sum[_col2['vipno']])\n",
    "mapping_index_v = {i:idx for (idx,i) in zip(range(len(set_vipno)),set_vipno)}\n",
    "\n",
    "\n",
    "def aggByUser(category='class4'):\n",
    "    global set_vipno,df_amount,_col2\n",
    "    map_single = {v:{} for v in set_vipno}\n",
    "    df_temp = df_amount[ int(category[-1])-1 ]\n",
    "    for v in set_vipno:\n",
    "        lst_v = df_temp.loc[ df_temp[_col2['vipno']]==v ]\n",
    "        for idx,row in lst_v.iterrows():\n",
    "            map_single[v][ row[ _col2[ category ] ] ] = row[ _col2['amount'] ]\n",
    "    return map_single\n",
    "\n",
    "\n",
    "def computeUserFeatureOfClass(category='class4'):\n",
    "    global df_amount,mapping_index_v,_col2\n",
    "    set_class_i = set(new_df[_col2[ category ]])\n",
    "    mapping_index_class_i = {i:idx for (idx,i) in zip(range(len(set_class_i)),set_class_i)}\n",
    "    mat_userFeature = np.array([[0.0 for i in range(len(set_class_i))] for j in range(len(set_vipno))])\n",
    "    for idx,r in df_amount[ int(category[-1])-1 ].iterrows():\n",
    "        mat_userFeature[ mapping_index_v[ r[ _col2['vipno'] ] ] ][ mapping_index_class_i[ r[ _col2[category] ] ] ] = r[ _col2['amount'] ]\n",
    "    return mat_userFeature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 将时间转化为 time level 1-4\n",
    "def processTimeLevel(new_df):\n",
    "    global _col2\n",
    "    _col2.update({\n",
    "        'tran_time_level':'tran_time_level',\n",
    "        'tran_date':'tran_date'\n",
    "    })\n",
    "    \n",
    "    tran_time = new_df[ _col2['tran_time'] ]\n",
    "    tran_time = list(map(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').timestamp(),tran_time))\n",
    "    new_df[ _col2['tran_time'] ] = tran_time\n",
    "    \n",
    "    tran_date = list( map(lambda x:datetime.datetime.strftime(datetime.datetime.fromtimestamp(x),'%Y%m%d'),tran_time) ) ### to y-m-d\n",
    "    new_df[ _col2['tran_date'] ] = tran_date\n",
    "    \n",
    "    df_temp = new_df[ [_col2['vipno'], _col2['tran_date']] ]\n",
    "    q = max(df_temp[ _col2['tran_date'] ])\n",
    "    df_temp = {row['vipno']:q for idx,row in df_temp.iterrows()}\n",
    "    tran_time_level = []\n",
    "    for idx,row in new_df.iterrows():\n",
    "        latest_date = q\n",
    "        latest_date = datetime.datetime.strptime(latest_date,'%Y%m%d').timestamp()\n",
    "        latest_date = datetime.datetime.fromtimestamp(latest_date)\n",
    "        time_level4 = (latest_date - datetime.timedelta(days=30)).timestamp()\n",
    "        time_level3 = (latest_date - datetime.timedelta(days=2*30)).timestamp()\n",
    "        time_level2 = (latest_date - datetime.timedelta(days=4*30)).timestamp()\n",
    "        time_levels = np.array([time_level2,time_level3,time_level4])\n",
    "        row_time = row[_col2['tran_time']]\n",
    "        tran_time_level.append( len(np.where(row_time>time_levels)[0])+1 ) ### append time level\n",
    "        \n",
    "    new_df[ _col2['tran_time_level'] ] = tran_time_level\n",
    "    return new_df\n",
    "\n",
    "\n",
    "new_df = processTimeLevel(new_df)\n",
    "new_df = new_df.sort_values(by=[_col2['vipno']]) ### sort by customer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### create single tree by one transaction row\n",
    "def createTreeBySingleTrans(row):\n",
    "    troot = TreeNode(nodeType='root')\n",
    "#     root.display()\n",
    "    vipno = row[ _col2['vipno'] ]\n",
    "    class1 = row[_col2['class1']]\n",
    "    class2 = row[_col2['class2']]\n",
    "    class3 = row[_col2['class3']]\n",
    "    class4 = row[_col2['class4']]\n",
    "    tran_date = row[_col2['tran_date']]\n",
    "    newnode = TreeNode(nodeType='innode',nodeClass=class1,level=1,freq=1,tm=tran_date,parent=troot)\n",
    "    troot.att_childs.append(newnode)\n",
    "    cur_node = troot.att_childs[0]\n",
    "    for idx,c in enumerate([class2,class3,class4],2):\n",
    "#         cur_node.out()\n",
    "        if idx==4:\n",
    "            nodeType='leaf'\n",
    "            f=0\n",
    "        else:\n",
    "            if idx==row[_col2['tran_time_level']]:\n",
    "                nodeType = 'leaf'\n",
    "                f=0\n",
    "            else:\n",
    "                f=1\n",
    "                nodeType='innode'\n",
    "        newnode = TreeNode(nodeType=nodeType,nodeClass=c,level=idx,freq=1,tm=tran_date,parent=cur_node)\n",
    "        cur_node.att_childs.append(newnode)\n",
    "        cur_node = cur_node.att_childs[0]\n",
    "        if f==0:\n",
    "            break\n",
    "    return {'vipno':vipno,'root':troot}\n",
    "    \n",
    "\n",
    "def mergeNode(node1,node2,parent_node,tag='union'):\n",
    "    if node1.att_class == node2.att_class and \\\n",
    "        node1.att_level == node2.att_level:\n",
    "        if 'leaf' in [node1.node_type,node2.node_type]:\n",
    "            node_type = 'innode' if tag=='union' else 'leaf'\n",
    "        else:\n",
    "            node_type = 'innode'\n",
    "#             if node1.node_type!=node2.node_type:\n",
    "#                 raise Exception('error',node1.out(),node2.out())\n",
    "        return TreeNode(nodeType=node1.node_type,\n",
    "                        nodeClass=node1.att_class,\n",
    "                        level=node1.att_level,\n",
    "                        freq=sum([node1.att_freq,node2.att_freq]),\n",
    "                        tm=str(max(int(node1.att_tm),int(node2.att_tm))),\n",
    "                        parent=parent_node)\n",
    "    else:\n",
    "        raise Exception('error',node1.out(),node2.out())\n",
    "        return\n",
    "\n",
    "    \n",
    "def findNodeByClass(root,nodeClass,level=5):\n",
    "    res = root.get_all_nodes()\n",
    "    res.append(root)\n",
    "    res = list(filter(lambda x:x.att_class==nodeClass,res)) ### find the node\n",
    "    if len(res):\n",
    "        return res[0]\n",
    "    else:\n",
    "#         print('not found class',nodeClass)\n",
    "        raise Warning('not found class')\n",
    "        return None\n",
    "        \n",
    "\n",
    "\n",
    "def unionTreeOfCusotomer(root,root1,root2,vipno=False):\n",
    "    q = [x for x in root1.att_childs]\n",
    "    q.extend([x for x in root2.att_childs])\n",
    "    counter = Counter(list(map(lambda x:x.att_class,q)))\n",
    "    inter = list(filter(lambda x:counter[x]>1,counter))\n",
    "    noninter = list(filter(lambda x:counter[x]==1,counter))\n",
    "    while len(q):\n",
    "        nn = q.pop(0)\n",
    "        if nn.att_class in inter:\n",
    "            nn2 = list(filter(lambda x:x.att_class==nn.att_class,q))[0]\n",
    "            q.remove(nn2)\n",
    "            newnode = mergeNode(nn,nn2,root)\n",
    "            root.att_childs.append(newnode)\n",
    "            unionTreeOfCusotomer(newnode,nn,nn2)\n",
    "        else:\n",
    "            newnode = TreeNode(nn.node_type,nn.att_class,[],nn.att_freq,nn.att_level,nn.att_tm,root)\n",
    "            nn.copy(nn,newnode)\n",
    "            root.att_childs.append(newnode)\n",
    "         \n",
    "    return \n",
    "\n",
    "\n",
    "def intersectTreeOfCusotomer(root,root1,root2,vipno=False):\n",
    "    q = [x for x in root1.att_childs]\n",
    "    q.extend([x for x in root2.att_childs])\n",
    "    counter = Counter(list(map(lambda x:x.att_class,q)))\n",
    "    inter = list(filter(lambda x:counter[x]>1,counter))\n",
    "    noninter = list(filter(lambda x:counter[x]==1,counter))\n",
    "    while len(q):\n",
    "        nn = q.pop(0)\n",
    "        if nn.att_class in inter:\n",
    "            nn2 = list(filter(lambda x:x.att_class==nn.att_class,q))[0]\n",
    "            q.remove(nn2)\n",
    "            newnode = mergeNode(nn,nn2,root)\n",
    "            root.att_childs.append(newnode)\n",
    "            intersectTreeOfCusotomer(newnode,nn,nn2)\n",
    "         \n",
    "    return \n",
    "\n",
    "\n",
    "def buildTreeOfCustomers(df,all_customers):\n",
    "    global _col2\n",
    "    customer_forest = {c:TreeNode(nodeType='root') for c in all_customers}\n",
    "    for idx,row in df.iterrows():\n",
    "        cust = row[ _col2['vipno'] ]\n",
    "        subtree = createTreeBySingleTrans(row)['root']\n",
    "        temp_root = TreeNode()\n",
    "        unionTreeOfCusotomer(temp_root,customer_forest[cust],subtree)\n",
    "        customer_forest[cust] = temp_root\n",
    "    return customer_forest\n",
    "\n",
    "\n",
    "def sim_v_ur(v,ur):\n",
    "    try:\n",
    "        parentnode_ur = ur.find_class(v.att_parent.att_class)\n",
    "        if parentnode_ur is None:\n",
    "            parentnode_ur = findNodeByClass(root=ur,nodeClass=v.att_parent.att_class)\n",
    "    except Warning as e:\n",
    "        print('not found ',v.att_parent.att_class)\n",
    "        return 0\n",
    "    freq_ur = [x.att_freq for x in parentnode_ur.att_childs]\n",
    "    try:\n",
    "        res = float(v.att_freq/np.sum(freq_ur))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "\n",
    "def sim_vl_ur(vl,ur):\n",
    "    if len(vl)==0:\n",
    "        return 0\n",
    "    try:\n",
    "        s = list(map(lambda x:sim_v_ur(x,ur),vl))\n",
    "        return np.mean(s)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "        \n",
    "def dist_ir_ur(ir,ur):\n",
    "    utree = TreeNode()\n",
    "    unionTreeOfCusotomer(utree,ir,ur)\n",
    "    itree = TreeNode()\n",
    "    intersectTreeOfCusotomer(itree,ir,ur)\n",
    "    ir = itree\n",
    "    ur = utree\n",
    "    nodes_ir = ir.get_all_nodes()\n",
    "    if len(nodes_ir)==0:\n",
    "        return 1\n",
    "    H = max(set(list(map(lambda x:x.att_level,nodes_ir))))\n",
    "    s = 0\n",
    "    for i in range(1,H+1):\n",
    "        w = i/np.sum(range(1,H+1))\n",
    "        vl = list(filter(lambda x:x.att_level==i,nodes_ir))\n",
    "        s += w*sim_vl_ur(vl,ur)\n",
    "    return 1-s\n",
    "\n",
    "\n",
    "def updateTreeByFrequence(root,freq):\n",
    "    nodes = [x for x in root.att_childs]\n",
    "    for nn in nodes:\n",
    "        if nn.att_freq<freq:\n",
    "            root.att_childs.remove(nn)\n",
    "            nn.att_parent = None\n",
    "        else:\n",
    "            updateTreeByFrequence(nn,freq)\n",
    "    return\n",
    "\n",
    "def getClusterCentroid(forest_customer):\n",
    "    global customers\n",
    "    centroid = TreeNode(nodeType='root')\n",
    "    for tr in forest_customer:\n",
    "        temp_root = TreeNode()\n",
    "        unionTreeOfCusotomer(temp_root,centroid,forest_customer[tr])\n",
    "        centroid = temp_root\n",
    "    \n",
    "    current_freq = 1\n",
    "    mindist = 1e10\n",
    "    freq_step = centroid.get_avg_freq()\n",
    "    freq_end = centroid.get_max_freq()\n",
    "    centroid_record = centroid\n",
    "    size_average = np.mean(list(map(lambda x:forest_customer[x].get_node_size(),forest_customer)))\n",
    "    print('freq ',freq_step,freq_end)\n",
    "    while current_freq<freq_end:\n",
    "        updateTreeByFrequence(centroid,current_freq)\n",
    "        dist = sum([dist_ir_ur(forest_customer[c],centroid) for c in forest_customer])\n",
    "        if dist<mindist:\n",
    "            mindist = dist\n",
    "            centroid_record = TreeNode()\n",
    "            centroid.copy(centroid,centroid_record)\n",
    "        if centroid.get_node_size()<size_average:\n",
    "            print('size quit')\n",
    "            break\n",
    "        current_freq += freq_step\n",
    "    return centroid_record\n",
    "\n",
    "    \n",
    "\n",
    "def clusterMain():\n",
    "    \n",
    "    ### get distant pair\n",
    "    def distantPair(topK_key,forest_concern):\n",
    "        max_dist = 0\n",
    "        max_pair = None\n",
    "        for i in topK_key:\n",
    "            for j in topK_key:\n",
    "                if j>i:\n",
    "                    dist = dist_ir_ur(forest_concern[i],forest_concern[j])\n",
    "                    if dist>max_dist:\n",
    "                        max_dist = dist\n",
    "                        max_pair = (i,j)\n",
    "        return [max_dist,max_pair]\n",
    "\n",
    "    ### recluster forest_concern\n",
    "    def recluster():\n",
    "        print('recluster')\n",
    "        subcluster = [[],[]]\n",
    "        for c in forest_concern:\n",
    "            current_tree = forest_concern[c]\n",
    "            [dist1,dist2] = [\n",
    "                dist_ir_ur(current_tree,forest_concern[max_pair[0]]),\n",
    "                dist_ir_ur(current_tree,forest_concern[max_pair[1]])\n",
    "            ]\n",
    "            if dist1<dist2:\n",
    "                subcluster[0].append(c)\n",
    "            else:\n",
    "                subcluster[1].append(c)\n",
    "        return subcluster\n",
    "\n",
    "    ### precluster [] ; postcluster [[]]\n",
    "    def computeBIC(precluster,postcluster):\n",
    "        print('compute BIC')\n",
    "        N = len(precluster)\n",
    "        D = sum([customer_buy_count[x] for x in precluster])\n",
    "        pre_coff_1 = (N-1)\n",
    "        pre_sigma_s = 1.0/pre_coff_1 * np.sum(np.power(list(dist_concern.values()),2))\n",
    "        pre_likelihood = -N/2*np.log(2*np.pi) - N*D/2*np.log(pre_sigma_s) - pre_coff_1/2\n",
    "        pre_bic = pre_likelihood - 1*(D+1)/2*np.log(1)\n",
    "\n",
    "        N_i = np.array([len(postcluster[0]), len(postcluster[1])])\n",
    "        D_i = np.array([\n",
    "            sum([customer_buy_count[x] for x in postcluster[0]]),\n",
    "            sum([customer_buy_count[x] for x in postcluster[1]])\n",
    "        ])\n",
    "        post_coff_1 = N_i - 2\n",
    "        post_sigma_s = 1.0/post_coff_1 * np.array([ \n",
    "            np.sum( np.power(list( dist_1.values() ),2) ), \n",
    "            np.sum( np.power(list( dist_2.values() ),2) )\n",
    "        ])\n",
    "        post_likelihood = N_i*np.log(N_i) - N_i*np.log(N) - N_i/2*np.log(2*np.pi) - N_i*D/2*np.log(post_sigma_s) - post_coff_1/2\n",
    "        post_likelihood = np.sum(post_likelihood)\n",
    "        post_bic = post_likelihood - 2*(D+1)/2*np.log(2)\n",
    "\n",
    "        print('bic ',pre_bic,post_bic)\n",
    "        return pre_bic,post_bic\n",
    "    \n",
    "    ### compute metrics and scores\n",
    "    def computeMetrics(cluster_final):\n",
    "        print('compute metrics')\n",
    "    #     cluster_final = cluster_static\n",
    "        mapping = {x:i for i,x in enumerate(customers,0)} ### customer:idx\n",
    "        d = np.array([[0.0 for i in range(len(customers))] for j in range(len(customers))])\n",
    "        ### 计算距离矩阵\n",
    "        for i,x in enumerate(customers,0):\n",
    "            for j,y in enumerate(customers,0):\n",
    "                if j>=i:\n",
    "                    d[ mapping[x] ][ mapping[y] ] = dist_ir_ur(forest_customer[x],forest_customer[y])\n",
    "                    d[ mapping[y] ][ mapping[x] ] = d[ mapping[x] ][ mapping[y] ]\n",
    "\n",
    "        sc = 0\n",
    "        B = np.array([0.0 for i in range(len(customers))])\n",
    "        A = np.array([0.0 for j in range(len(customers))])\n",
    "        cust_all = set(customers)\n",
    "        for m,cl in enumerate(cluster_final,0):\n",
    "            cust_cl = set(cl)\n",
    "            for p in cl:\n",
    "                same = cust_cl - set([p])\n",
    "                #### find nearest neighbor centroid\n",
    "                record_nearest = None\n",
    "                record_mindist = 100\n",
    "                for n,ct in enumerate(centroid_final,0):\n",
    "                    if m!=n:\n",
    "                        temp_dist = dist_ir_ur(forest_customer[p],ct)\n",
    "                        if temp_dist<record_mindist:\n",
    "                            record_mindist = temp_dist\n",
    "                            record_nearest = n\n",
    "\n",
    "                other = cluster_final[n]\n",
    "                A[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[s] ] for s in same])\n",
    "                B[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[o] ] for o in other])\n",
    "        sc = np.mean([(B[i]-A[i])/np.max([A[i],B[i]]) for i in range(len(customers))])\n",
    "        print('sc ',sc)\n",
    "\n",
    "        cp = np.mean([ \n",
    "            np.mean( list(map(lambda x:dist_ir_ur(forest_customer[x],centroid_final[i]),cl)) ) \n",
    "            for i,cl in enumerate(cluster_final,0) \n",
    "        ])\n",
    "        print('cp ',cp)\n",
    "\n",
    "        return sc,cp\n",
    "    \n",
    "    ### compute 2-means\n",
    "    def kmeans2(subcluster):\n",
    "        print('2-means')\n",
    "        #### update recluster result\n",
    "        subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "        subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "        centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "        centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "        #### get all points in subcluster\n",
    "        all_points = copy.deepcopy(subcluster[0])\n",
    "        all_points.extend(subcluster[1])\n",
    "        _record_iter = 0\n",
    "        while 1:\n",
    "            #### re-distribute according centroid12\n",
    "            new_subcluster = [[],[]]\n",
    "            for x in all_points:\n",
    "                dist1 = dist_ir_ur(forest_customer[x],centroid_1)\n",
    "                dist2 = dist_ir_ur(forest_customer[x],centroid_2)\n",
    "                if dist1<dist2:\n",
    "                    new_subcluster[0].append(x)\n",
    "                else:\n",
    "                    new_subcluster[1].append(x)\n",
    "            #### updating centroid12\n",
    "            subforest_1 = { x:forest_customer[x] for x in new_subcluster[0] }\n",
    "            subforest_2 = { x:forest_customer[x] for x in new_subcluster[1] }\n",
    "            centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "            centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "            if new_subcluster == subcluster:\n",
    "                break\n",
    "            _record_iter += 1\n",
    "        return new_subcluster\n",
    "\n",
    "    top_ratio = 0.5\n",
    "    topK_max = 50\n",
    "    split_threshold = 20\n",
    "    global new_df\n",
    "    customer_buy_count = new_df.groupby(by=[_col2['vipno']]).count()['uid'].to_dict() ### { customer:buy_count }\n",
    "    customers = list( set(new_df[_col2['vipno']]) ) ### all customers : list\n",
    "    forest_customer = buildTreeOfCustomers(new_df,customers) ### customer tree {vipno:root}\n",
    "    cluster_dynamic = [[x for x in customers]]\n",
    "    cluster_static = []\n",
    "    centroid_final = []\n",
    "    while len(cluster_dynamic):\n",
    "        cluster_concern = cluster_dynamic.pop(0)\n",
    "        cluster_concern = set(cluster_concern)\n",
    "        forest_concern = list(filter(lambda x:x in cluster_concern,forest_customer))\n",
    "        forest_concern = { x:forest_customer[x] for x in forest_concern }\n",
    "        centroid_concern = getClusterCentroid(forest_concern) ### centoid tree of interest\n",
    "        dist_concern = { x:dist_ir_ur(forest_concern[x],centroid_concern) for x in forest_concern } ### dist of @forest_concern & @centroid_concern\n",
    "        topK = min( [ topK_max,max([2,top_ratio*len(forest_concern)]) ] )\n",
    "        topK = int(topK)\n",
    "        topK_key = sorted(dist_concern,key=lambda x:dist_concern[x],reverse=True)[:topK]\n",
    "        [max_dist,max_pair] = distantPair(topK_key,forest_concern) ### find most distant pair\n",
    "        subcluster = recluster()\n",
    "#         subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "#         subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "#         centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "#         centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "#         dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "#         dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "        subcluster = kmeans2(subcluster)\n",
    "        [ pre_bic,post_bic ] = computeBIC(list(cluster_concern),subcluster)\n",
    "        if post_bic<pre_bic or (len(subforest_1)<split_threshold or len(subforest_2)<split_threshold):\n",
    "            cluster_static.append(list(cluster_concern))\n",
    "            centroid_final.append(centroid_concern)\n",
    "            print('settle ',len(cluster_concern))\n",
    "        else:\n",
    "            cluster_dynamic.extend(subcluster)\n",
    "            print('split ',len(subcluster[0]),len(subcluster[1]))\n",
    "            \n",
    "    return computeMetrics(cluster_static)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq  1255.5 4499\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  1155.7777777777778 4212\n",
      "size quit\n",
      "freq  99.72222222222223 325\n",
      "size quit\n",
      "freq  741.4444444444445 3001\n",
      "size quit\n",
      "freq  514.0555555555555 1804\n",
      "size quit\n",
      "original cluster  462 24\n",
      "new cluster  282 204\n",
      "freq  463.72222222222223 2004\n",
      "size quit\n",
      "freq  791.7777777777778 2945\n",
      "size quit\n",
      "original cluster  462 24\n",
      "new cluster  207 279\n",
      "freq  1125.888888888889 3949\n",
      "size quit\n",
      "freq  129.61111111111111 550\n",
      "size quit\n",
      "original cluster  462 24\n",
      "new cluster  404 82\n",
      "freq  1165.0555555555557 4257\n",
      "size quit\n",
      "freq  90.44444444444444 430\n",
      "size quit\n",
      "original cluster  462 24\n",
      "new cluster  415 71\n",
      "compute BIC\n",
      "split  415 71\n",
      "freq  1165.0555555555557 4257\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  717.8888888888889 2759\n",
      "size quit\n",
      "freq  447.1666666666667 1498\n",
      "size quit\n",
      "freq  124.33333333333333 575\n",
      "size quit\n",
      "freq  1040.7222222222222 3682\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  83 332\n",
      "freq  1117.611111111111 3948\n",
      "size quit\n",
      "freq  53.375 309\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  394 21\n",
      "freq  987.0555555555555 3848\n",
      "size quit\n",
      "freq  178.0 666\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  346 69\n",
      "freq  776.1111111111111 2899\n",
      "size quit\n",
      "freq  388.94444444444446 1358\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  253 162\n",
      "freq  117.88888888888889 536\n",
      "size quit\n",
      "freq  1047.1666666666667 3721\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  82 333\n",
      "freq  1117.611111111111 3948\n",
      "size quit\n",
      "freq  53.375 309\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  394 21\n",
      "freq  987.0555555555555 3848\n",
      "size quit\n",
      "freq  178.0 666\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  346 69\n",
      "freq  776.1111111111111 2899\n",
      "size quit\n",
      "freq  388.94444444444446 1358\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  253 162\n",
      "freq  117.88888888888889 536\n",
      "size quit\n",
      "freq  1047.1666666666667 3721\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  82 333\n",
      "freq  1117.611111111111 3948\n",
      "size quit\n",
      "freq  53.375 309\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  394 21\n",
      "freq  987.0555555555555 3848\n",
      "size quit\n",
      "freq  178.0 666\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  346 69\n",
      "freq  776.1111111111111 2899\n",
      "size quit\n",
      "freq  388.94444444444446 1358\n",
      "size quit\n",
      "original cluster  256 159\n",
      "new cluster  253 162\n",
      "compute BIC\n",
      "split  253 162\n",
      "freq  90.44444444444444 430\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  42.35294117647059 245\n",
      "size quit\n",
      "freq  53.411764705882355 185\n",
      "size quit\n",
      "freq  75.38888888888889 342\n",
      "size quit\n",
      "freq  18.066666666666666 88\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  50 21\n",
      "freq  8.642857142857142 28\n",
      "size quit\n",
      "freq  88.6470588235294 403\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  8 63\n",
      "freq  83.88888888888889 411\n",
      "size quit\n",
      "freq  9.076923076923077 25\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  60 11\n",
      "freq  12.714285714285714 49\n",
      "size quit\n",
      "freq  85.29411764705883 401\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  10 61\n",
      "freq  81.05555555555556 406\n",
      "size quit\n",
      "freq  11.266666666666667 32\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  55 16\n",
      "freq  6.583333333333333 21\n",
      "size quit\n",
      "freq  91.11764705882354 409\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  8 63\n",
      "freq  82.11111111111111 393\n",
      "size quit\n",
      "freq  9.375 37\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  55 16\n",
      "freq  9.23076923076923 30\n",
      "size quit\n",
      "freq  88.70588235294117 400\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  11 60\n",
      "freq  79.61111111111111 389\n",
      "size quit\n",
      "freq  12.1875 41\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  54 17\n",
      "freq  9.23076923076923 30\n",
      "size quit\n",
      "freq  88.70588235294117 400\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  11 60\n",
      "freq  79.61111111111111 389\n",
      "size quit\n",
      "freq  12.1875 41\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  54 17\n",
      "freq  9.23076923076923 30\n",
      "size quit\n",
      "freq  88.70588235294117 400\n",
      "size quit\n",
      "original cluster  28 43\n",
      "new cluster  11 60\n",
      "compute BIC\n",
      "split  11 60\n",
      "freq  776.1111111111111 2899\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  550.3888888888889 2086\n",
      "size quit\n",
      "freq  225.72222222222223 813\n",
      "size quit\n",
      "freq  286.1666666666667 1330\n",
      "size quit\n",
      "freq  489.94444444444446 1674\n",
      "size quit\n",
      "original cluster  183 70\n",
      "new cluster  72 181\n",
      "freq  176.94444444444446 744\n",
      "size quit\n",
      "freq  599.1666666666666 2295\n",
      "size quit\n",
      "original cluster  183 70\n",
      "new cluster  73 180\n",
      "freq  326.0 1198\n",
      "size quit\n",
      "freq  450.1111111111111 1759\n",
      "size quit\n",
      "original cluster  183 70\n",
      "new cluster  109 144\n",
      "freq  487.0 1757\n",
      "size quit\n",
      "freq  289.1111111111111 1142\n",
      "size quit\n",
      "original cluster  183 70\n",
      "new cluster  156 97\n",
      "freq  538.0 2079\n",
      "size quit\n",
      "freq  238.11111111111111 869\n",
      "size quit\n",
      "original cluster  183 70\n",
      "new cluster  151 102\n",
      "compute BIC\n",
      "settle  253\n",
      "freq  388.94444444444446 1358\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  125.27777777777777 461\n",
      "size quit\n",
      "freq  263.6666666666667 897\n",
      "size quit\n",
      "freq  26.533333333333335 95\n",
      "size quit\n",
      "freq  366.8333333333333 1263\n",
      "size quit\n",
      "original cluster  61 101\n",
      "new cluster  11 151\n",
      "freq  34.92307692307692 89\n",
      "size quit\n",
      "freq  363.72222222222223 1307\n",
      "size quit\n",
      "original cluster  61 101\n",
      "new cluster  12 150\n",
      "freq  3.0 5\n",
      "size quit\n",
      "freq  387.94444444444446 1358\n",
      "size quit\n",
      "original cluster  61 101\n",
      "new cluster  1 161\n",
      "freq  106.11111111111111 417\n",
      "size quit\n",
      "freq  282.8333333333333 941\n",
      "size quit\n",
      "original cluster  61 101\n",
      "new cluster  55 107\n",
      "freq  282.1111111111111 980\n",
      "size quit\n",
      "freq  113.11764705882354 452\n",
      "size quit\n",
      "original cluster  61 101\n",
      "new cluster  118 44\n",
      "freq  301.05555555555554 1016\n",
      "size quit\n",
      "freq  93.05882352941177 360\n",
      "size quit\n",
      "original cluster  61 101\n",
      "new cluster  123 39\n",
      "compute BIC\n",
      "split  123 39\n",
      "freq  9.23076923076923 30\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  6.5 19\n",
      "size quit\n",
      "freq  4.666666666666667 16\n",
      "size quit\n",
      "freq  5.090909090909091 9\n",
      "size quit\n",
      "freq  7.111111111111111 21\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  4 7\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "freq  5.25 12\n",
      "size quit\n",
      "freq  6.333333333333333 18\n",
      "size quit\n",
      "original cluster  7 4\n",
      "new cluster  5 6\n",
      "compute BIC\n",
      "settle  11\n",
      "freq  88.70588235294117 400\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  86.23529411764706 392\n",
      "size quit\n",
      "freq  4.2 21\n",
      "size quit\n",
      "freq  16.857142857142858 61\n",
      "size quit\n",
      "freq  74.82352941176471 339\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  15 45\n",
      "freq  80.3529411764706 362\n",
      "size quit\n",
      "freq  9.466666666666667 38\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  47 13\n",
      "freq  2.25 6\n",
      "size quit\n",
      "freq  87.6470588235294 394\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  4 56\n",
      "freq  66.47058823529412 341\n",
      "size quit\n",
      "freq  25.2 74\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  39 21\n",
      "freq  56.06666666666667 319\n",
      "size quit\n",
      "freq  39.23529411764706 125\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  24 36\n",
      "freq  76.41176470588235 386\n",
      "size quit\n",
      "freq  16.076923076923077 56\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  38 22\n",
      "freq  18.4 132\n",
      "size quit\n",
      "freq  72.47058823529412 268\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  12 48\n",
      "freq  16.8125 75\n",
      "size quit\n",
      "freq  72.88235294117646 376\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  20 40\n",
      "freq  80.76470588235294 372\n",
      "size quit\n",
      "freq  10.384615384615385 29\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  52 8\n",
      "freq  13.866666666666667 84\n",
      "size quit\n",
      "freq  76.47058823529412 387\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  18 42\n",
      "freq  78.23529411764706 355\n",
      "size quit\n",
      "freq  12.714285714285714 45\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  52 8\n",
      "freq  14.153846153846153 39\n",
      "size quit\n",
      "freq  77.88235294117646 380\n",
      "size quit\n",
      "original cluster  55 5\n",
      "new cluster  11 49\n",
      "compute BIC\n",
      "split  11 49\n",
      "freq  301.05555555555554 1016\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  127.83333333333333 419\n",
      "size quit\n",
      "freq  173.22222222222223 597\n",
      "size quit\n",
      "freq  215.55555555555554 728\n",
      "size quit\n",
      "freq  90.52941176470588 330\n",
      "size quit\n",
      "original cluster  65 58\n",
      "new cluster  94 29\n",
      "freq  274.77777777777777 930\n",
      "size quit\n",
      "freq  27.823529411764707 90\n",
      "size quit\n",
      "original cluster  65 58\n",
      "new cluster  98 25\n",
      "freq  254.83333333333334 870\n",
      "size quit\n",
      "freq  46.22222222222222 169\n",
      "size quit\n",
      "original cluster  65 58\n",
      "new cluster  93 30\n",
      "compute BIC\n",
      "settle  123\n",
      "freq  93.05882352941177 360\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  19.09090909090909 57\n",
      "size quit\n",
      "freq  80.70588235294117 303\n",
      "size quit\n",
      "freq  55.733333333333334 185\n",
      "size quit\n",
      "freq  49.733333333333334 175\n",
      "size quit\n",
      "original cluster  4 35\n",
      "new cluster  17 22\n",
      "freq  69.375 260\n",
      "size quit\n",
      "freq  36.30769230769231 100\n",
      "size quit\n",
      "original cluster  4 35\n",
      "new cluster  25 14\n",
      "freq  25.357142857142858 95\n",
      "size quit\n",
      "freq  81.8 265\n",
      "size quit\n",
      "original cluster  4 35\n",
      "new cluster  11 28\n",
      "freq  54.5625 145\n",
      "size quit\n",
      "freq  47.266666666666666 228\n",
      "size quit\n",
      "original cluster  4 35\n",
      "new cluster  23 16\n",
      "freq  72.13333333333334 265\n",
      "size quit\n",
      "freq  35.714285714285715 97\n",
      "size quit\n",
      "original cluster  4 35\n",
      "new cluster  26 13\n",
      "freq  68.1875 291\n",
      "size quit\n",
      "freq  30.6875 96\n",
      "size quit\n",
      "original cluster  4 35\n",
      "new cluster  26 13\n",
      "compute BIC\n",
      "settle  39\n",
      "freq  14.153846153846153 39\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  13.0 39\n",
      "size quit\n",
      "freq  2.5 5\n",
      "size quit\n",
      "freq  13.454545454545455 36\n",
      "size quit\n",
      "freq  4.0 9\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  6 5\n",
      "freq  9.333333333333334 21\n",
      "size quit\n",
      "freq  7.6923076923076925 33\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  4 7\n",
      "freq  7.0 17\n",
      "size quit\n",
      "freq  9.846153846153847 36\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  1 10\n",
      "freq  8.0 19\n",
      "size quit\n",
      "freq  9.23076923076923 30\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  2 9\n",
      "freq  12.909090909090908 31\n",
      "size quit\n",
      "freq  4.2 10\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  5 6\n",
      "freq  7.777777777777778 22\n",
      "size quit\n",
      "freq  8.76923076923077 30\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  3 8\n",
      "freq  12.909090909090908 31\n",
      "size quit\n",
      "freq  4.2 10\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  5 6\n",
      "freq  7.777777777777778 22\n",
      "size quit\n",
      "freq  8.76923076923077 30\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  3 8\n",
      "freq  12.909090909090908 31\n",
      "size quit\n",
      "freq  4.2 10\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  5 6\n",
      "freq  7.777777777777778 22\n",
      "size quit\n",
      "freq  8.76923076923077 30\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  3 8\n",
      "freq  12.909090909090908 31\n",
      "size quit\n",
      "freq  4.2 10\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  5 6\n",
      "freq  7.777777777777778 22\n",
      "size quit\n",
      "freq  8.76923076923077 30\n",
      "size quit\n",
      "original cluster  8 3\n",
      "new cluster  3 8\n",
      "compute BIC\n",
      "settle  11\n",
      "freq  77.88235294117646 380\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  76.29411764705883 372\n",
      "size quit\n",
      "freq  3.0 8\n",
      "size quit\n",
      "freq  7.928571428571429 20\n",
      "size quit\n",
      "freq  71.3529411764706 360\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  8 41\n",
      "freq  72.6470588235294 363\n",
      "size quit\n",
      "freq  6.357142857142857 25\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  40 9\n",
      "freq  9.538461538461538 41\n",
      "size quit\n",
      "freq  70.58823529411765 339\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  7 42\n",
      "freq  72.05882352941177 361\n",
      "size quit\n",
      "freq  7.615384615384615 27\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  41 8\n",
      "freq  2.6 6\n",
      "size quit\n",
      "freq  77.11764705882354 377\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  3 46\n",
      "freq  54.294117647058826 301\n",
      "size quit\n",
      "freq  26.733333333333334 91\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  30 19\n",
      "freq  4.75 25\n",
      "size quit\n",
      "freq  74.52941176470588 355\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  6 43\n",
      "freq  67.1875 320\n",
      "size quit\n",
      "freq  15.5625 69\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  37 12\n",
      "freq  12.4 74\n",
      "size quit\n",
      "freq  66.94117647058823 306\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  8 41\n",
      "freq  74.76470588235294 366\n",
      "size quit\n",
      "freq  4.416666666666667 14\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  44 5\n",
      "freq  7.333333333333333 25\n",
      "size quit\n",
      "freq  72.70588235294117 355\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  7 42\n",
      "freq  67.6875 321\n",
      "size quit\n",
      "freq  15.0625 67\n",
      "size quit\n",
      "original cluster  45 4\n",
      "new cluster  38 11\n",
      "compute BIC\n",
      "split  38 11\n",
      "freq  67.6875 321\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  31.0 115\n",
      "size quit\n",
      "freq  41.2 206\n",
      "size quit\n",
      "freq  6.5 19\n",
      "size quit\n",
      "freq  63.625 313\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  8 30\n",
      "freq  36.714285714285715 94\n",
      "size quit\n",
      "freq  40.642857142857146 231\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  19 19\n",
      "freq  13.25 49\n",
      "size quit\n",
      "freq  58.06666666666667 292\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  13 25\n",
      "freq  17.625 80\n",
      "size quit\n",
      "freq  53.4 292\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  15 23\n",
      "freq  50.13333333333333 241\n",
      "size quit\n",
      "freq  22.066666666666666 80\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  27 11\n",
      "freq  44.13333333333333 203\n",
      "size quit\n",
      "freq  28.066666666666666 118\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  21 17\n",
      "freq  44.13333333333333 203\n",
      "size quit\n",
      "freq  28.066666666666666 118\n",
      "size quit\n",
      "original cluster  20 18\n",
      "new cluster  21 17\n",
      "compute BIC\n",
      "split  21 17\n",
      "freq  15.0625 67\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  14.357142857142858 67\n",
      "size quit\n",
      "freq  6.666666666666667 13\n",
      "size quit\n",
      "freq  2.25 3\n",
      "freq  14.5 67\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  2 9\n",
      "freq  12.692307692307692 49\n",
      "size quit\n",
      "freq  5.846153846153846 18\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  6 5\n",
      "freq  12.333333333333334 49\n",
      "size quit\n",
      "freq  7.153846153846154 20\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  5 6\n",
      "freq  10.727272727272727 38\n",
      "size quit\n",
      "freq  9.461538461538462 50\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  6 5\n",
      "freq  13.307692307692308 49\n",
      "size quit\n",
      "freq  5.230769230769231 18\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  7 4\n",
      "freq  12.727272727272727 49\n",
      "size quit\n",
      "freq  7.769230769230769 22\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  4 7\n",
      "freq  12.692307692307692 49\n",
      "size quit\n",
      "freq  5.846153846153846 18\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  6 5\n",
      "freq  12.333333333333334 49\n",
      "size quit\n",
      "freq  7.153846153846154 20\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  5 6\n",
      "freq  10.727272727272727 38\n",
      "size quit\n",
      "freq  9.461538461538462 50\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  6 5\n",
      "freq  13.307692307692308 49\n",
      "size quit\n",
      "freq  5.230769230769231 18\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  7 4\n",
      "freq  12.727272727272727 49\n",
      "size quit\n",
      "freq  7.769230769230769 22\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  4 7\n",
      "freq  12.692307692307692 49\n",
      "size quit\n",
      "freq  5.846153846153846 18\n",
      "size quit\n",
      "original cluster  6 5\n",
      "new cluster  6 5\n",
      "compute BIC\n",
      "settle  11\n",
      "freq  44.13333333333333 203\n",
      "size quit\n",
      "recluster\n",
      "2-means\n",
      "freq  19.384615384615383 102\n",
      "size quit\n",
      "freq  29.285714285714285 101\n",
      "size quit\n",
      "freq  4.833333333333333 20\n",
      "size quit\n",
      "freq  42.2 201\n",
      "size quit\n",
      "original cluster  8 13\n",
      "new cluster  1 20\n",
      "freq  42.57142857142857 193\n",
      "size quit\n",
      "freq  5.076923076923077 12\n",
      "size quit\n",
      "original cluster  8 13\n",
      "new cluster  20 1\n",
      "freq  44.13333333333333 203\n",
      "size quit\n",
      "freq  0 0\n",
      "original cluster  8 13\n",
      "new cluster  21 0\n",
      "freq  44.13333333333333 203\n",
      "size quit\n",
      "freq  0 0\n",
      "original cluster  8 13\n",
      "new cluster  21 0\n",
      "compute BIC\n",
      "settle  21\n",
      "freq  28.066666666666666 118\n",
      "size quit"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE_Project_Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\IDE_Project_Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recluster\n",
      "2-means\n",
      "freq  6.266666666666667 32\n",
      "size quit\n",
      "freq  25.153846153846153 86\n",
      "size quit\n",
      "freq  26.4 116\n",
      "size quit\n",
      "freq  3.5714285714285716 11\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  14 3\n",
      "freq  1.3333333333333333 2\n",
      "freq  27.8 116\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  1 16\n",
      "freq  9.357142857142858 64\n",
      "size quit\n",
      "freq  22.307692307692307 64\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  8 9\n",
      "freq  24.333333333333332 105\n",
      "size quit\n",
      "freq  5.6 14\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  11 6\n",
      "freq  2.0 3\n",
      "freq  27.4 115\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  2 15\n",
      "freq  8.307692307692308 25\n",
      "size quit\n",
      "freq  22.357142857142858 96\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  10 7\n",
      "freq  18.23076923076923 58\n",
      "size quit\n",
      "freq  13.142857142857142 84\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  7 10\n",
      "freq  12.666666666666666 68\n",
      "size quit\n",
      "freq  19.214285714285715 59\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  8 9\n",
      "freq  21.846153846153847 73\n",
      "size quit\n",
      "freq  9.785714285714286 45\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  8 9\n",
      "freq  7.083333333333333 26\n",
      "size quit\n",
      "freq  24.0 92\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  5 12\n",
      "freq  26.0 116\n",
      "size quit\n",
      "freq  3.4444444444444446 12\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  13 4\n",
      "freq  1.3333333333333333 2\n",
      "freq  27.8 116\n",
      "size quit\n",
      "original cluster  7 10\n",
      "new cluster  1 16\n",
      "compute BIC\n",
      "settle  17\n",
      "8\n",
      "compute metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE_Project_Programming\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc  0.06855219660456724\n",
      "cp  0.3040049454730316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06855219660456724, 0.3040049454730316)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get distant pair\n",
    "def distantPair(topK_key,forest_concern):\n",
    "    max_dist = 0\n",
    "    max_pair = None\n",
    "    for i in topK_key:\n",
    "        for j in topK_key:\n",
    "            if j>i:\n",
    "                dist = dist_ir_ur(forest_concern[i],forest_concern[j])\n",
    "                if dist>max_dist:\n",
    "                    max_dist = dist\n",
    "                    max_pair = (i,j)\n",
    "    return [max_dist,max_pair]\n",
    "\n",
    "### recluster forest_concern\n",
    "def recluster():\n",
    "    print('recluster')\n",
    "    subcluster = [[],[]]\n",
    "    for c in forest_concern:\n",
    "        current_tree = forest_concern[c]\n",
    "        [dist1,dist2] = [\n",
    "            dist_ir_ur(current_tree,forest_concern[max_pair[0]]),\n",
    "            dist_ir_ur(current_tree,forest_concern[max_pair[1]])\n",
    "        ]\n",
    "        if dist1<dist2:\n",
    "            subcluster[0].append(c)\n",
    "        else:\n",
    "            subcluster[1].append(c)\n",
    "    return subcluster\n",
    "\n",
    "### precluster [] ; postcluster [[]]\n",
    "def computeBIC(precluster,postcluster):\n",
    "    print('compute BIC')\n",
    "    N = len(precluster)\n",
    "#     D = set([])\n",
    "#     [D.union(customer_buy[x]) for x in precluster]\n",
    "#     D = len(D)\n",
    "    D = sum([customer_buy_count[x] for x in precluster])\n",
    "    pre_coff_1 = (N-1)\n",
    "    pre_sigma_s = 1.0/pre_coff_1 * np.sum(np.power(list(dist_concern.values()),2))\n",
    "    pre_likelihood = -N/2*np.log(2*np.pi) - N*D/2*np.log(pre_sigma_s) - pre_coff_1/2\n",
    "    pre_bic = pre_likelihood - 1*(D+1)/2*np.log(1)\n",
    "\n",
    "    N_i = np.array([len(postcluster[0]), len(postcluster[1])])\n",
    "#     D_i = np.array([\n",
    "#         sum([customer_buy_count[x] for x in postcluster[0]]),\n",
    "#         sum([customer_buy_count[x] for x in postcluster[1]])\n",
    "#     ])\n",
    "    post_coff_1 = N_i - 2\n",
    "    post_sigma_s = 1.0/post_coff_1 * np.array([ \n",
    "        np.sum( np.power(list( dist_1.values() ),2) ), \n",
    "        np.sum( np.power(list( dist_2.values() ),2) )\n",
    "    ])\n",
    "    post_likelihood = N_i*np.log(N_i) - N_i*np.log(N) - N_i/2*np.log(2*np.pi) - N_i*D/2*np.log(post_sigma_s) - post_coff_1/2\n",
    "    post_likelihood = np.sum(post_likelihood)\n",
    "    post_bic = post_likelihood - 2*(D+1)/2*np.log(2)\n",
    "\n",
    "#     print('bic ',pre_bic,post_bic)\n",
    "    return pre_bic,post_bic\n",
    "\n",
    "### compute metrics and scores\n",
    "def computeMetrics(cluster_final):\n",
    "    print('compute metrics')\n",
    "#     cluster_final = cluster_static\n",
    "    mapping = {x:i for i,x in enumerate(customers,0)} ### customer:idx\n",
    "    d = np.array([[0.0 for i in range(len(customers))] for j in range(len(customers))])\n",
    "    ### 计算距离矩阵\n",
    "    for i,x in enumerate(customers,0):\n",
    "        for j,y in enumerate(customers,0):\n",
    "            if j>=i:\n",
    "                d[ mapping[x] ][ mapping[y] ] = dist_ir_ur(forest_customer[x],forest_customer[y])\n",
    "                d[ mapping[y] ][ mapping[x] ] = d[ mapping[x] ][ mapping[y] ]\n",
    "\n",
    "    sc = 0\n",
    "    B = np.array([0.0 for i in range(len(customers))])\n",
    "    A = np.array([0.0 for j in range(len(customers))])\n",
    "    cust_all = set(customers)\n",
    "    for m,cl in enumerate(cluster_final,0):\n",
    "        cust_cl = set(cl)\n",
    "        for p in cl:\n",
    "            same = cust_cl - set([p])\n",
    "            #### find nearest neighbor centroid\n",
    "            record_nearest = None\n",
    "            record_mindist = 100\n",
    "            for n,ct in enumerate(centroid_final,0):\n",
    "                if m!=n:\n",
    "                    temp_dist = dist_ir_ur(forest_customer[p],ct)\n",
    "                    if temp_dist<record_mindist:\n",
    "                        record_mindist = temp_dist\n",
    "                        record_nearest = n\n",
    "\n",
    "            other = cluster_final[n]\n",
    "            A[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[s] ] for s in same])\n",
    "            B[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[o] ] for o in other])\n",
    "    sc = np.mean([(B[i]-A[i])/np.max([A[i],B[i]]) for i in range(len(customers))])\n",
    "    print('sc ',sc)\n",
    "\n",
    "    cp = np.mean([ \n",
    "        np.mean( list(map(lambda x:dist_ir_ur(forest_customer[x],centroid_final[i]),cl)) ) \n",
    "        for i,cl in enumerate(cluster_final,0) \n",
    "    ])\n",
    "    print('cp ',cp)\n",
    "\n",
    "    return sc,cp\n",
    "\n",
    "### compute 2-means\n",
    "def kmeans2(subcluster):\n",
    "    print('2-means')\n",
    "    #### update recluster result\n",
    "    subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "    subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "    centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "    centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "    #### get all points in subcluster\n",
    "    all_points = copy.deepcopy(subcluster[0])\n",
    "    all_points.extend(subcluster[1])\n",
    "    _record_iter = 0\n",
    "    _record_cluster = []\n",
    "    new_subcluster = []\n",
    "    while 1:\n",
    "        _record_cluster = copy.deepcopy(new_subcluster)\n",
    "        #### re-distribute according centroid12\n",
    "        new_subcluster = [[],[]]\n",
    "        for x in all_points:\n",
    "            dist1 = dist_ir_ur(forest_customer[x],centroid_1)\n",
    "            dist2 = dist_ir_ur(forest_customer[x],centroid_2)\n",
    "            if dist1<dist2:\n",
    "                new_subcluster[0].append(x)\n",
    "            else:\n",
    "                new_subcluster[1].append(x)\n",
    "        #### updating centroid12\n",
    "        subforest_1 = { x:forest_customer[x] for x in new_subcluster[0] }\n",
    "        subforest_2 = { x:forest_customer[x] for x in new_subcluster[1] }\n",
    "        centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "        centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "        print('original cluster ',len(subcluster[0]),len(subcluster[1]))\n",
    "        print('new cluster ',len(new_subcluster[0]),len(new_subcluster[1]))\n",
    "        #### condition\n",
    "        if ( _record_iter>1 and abs(len(new_subcluster[0]) - len(_record_cluster[0])) < int(0.05*len(all_points)) ) \\\n",
    "            or _record_iter>10:\n",
    "            break\n",
    "        _record_iter += 1\n",
    "    return new_subcluster,subforest_1,subforest_2,centroid_1,centroid_2\n",
    "\n",
    "top_ratio = 0.7\n",
    "topK_max = 80\n",
    "split_threshold = 10\n",
    "method = 'random'\n",
    "global new_df\n",
    "customer_buy_count = new_df.groupby(by=[_col2['vipno']]).count()['class4'].to_dict() ### { customer:buy_count }\n",
    "customers = list( set(new_df[_col2['vipno']]) ) ### all customers : list\n",
    "customer_buy = {x:set([]) for x in customers}\n",
    "[customer_buy[ row[_col2['vipno']] ].add(row[_col2['class4']]) for idx,row in new_df.iterrows()] ### { customer:buy_items }\n",
    "forest_customer = buildTreeOfCustomers(new_df,customers) ### customer tree {vipno:root}\n",
    "[forest_customer[x].speed() for x in forest_customer] ### speed up searching\n",
    "cluster_dynamic = [[x for x in customers]]\n",
    "cluster_static = []\n",
    "centroid_final = []\n",
    "while len(cluster_dynamic):\n",
    "    cluster_concern = cluster_dynamic.pop(0)\n",
    "    cluster_concern = set(cluster_concern)\n",
    "    forest_concern = list(filter(lambda x:x in cluster_concern,forest_customer))\n",
    "    forest_concern = { x:forest_customer[x] for x in forest_concern }\n",
    "    centroid_concern = getClusterCentroid(forest_concern) ### centoid tree of interest\n",
    "    topK = min( [ topK_max,max([2,top_ratio*len(forest_concern)]) ] )\n",
    "    topK = int(topK)\n",
    "    dist_concern = { x:dist_ir_ur(forest_concern[x],centroid_concern) for x in forest_concern } ### dist of @forest_concern & @centroid_concern\n",
    "    if method == 'random':\n",
    "        topK_key = np.array(list(forest_concern.keys()))[np.random.permutation(len(forest_concern))[:topK]]\n",
    "    if method == 'fixed':\n",
    "        topK_key = sorted(dist_concern,key=lambda x:dist_concern[x],reverse=True)[:topK]\n",
    "    [max_dist,max_pair] = distantPair(topK_key,forest_concern) ### find most distant pair\n",
    "    subcluster = recluster()\n",
    "    [forest_concern[x].speed() for x in forest_concern] ### speed up searching\n",
    "#         subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "#         subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "#         centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "#         centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "#         dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "#         dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "#     break\n",
    "\n",
    "#     if len(subcluster[0])<split_threshold or len(subcluster[1])<split_threshold:\n",
    "#         cluster_static.append(list(cluster_concern))\n",
    "#         centroid_final.append(centroid_concern)\n",
    "#         print('settle ',len(cluster_concern))\n",
    "#         continue\n",
    "    [subcluster,subforest_1,subforest_2,centroid_1,centroid_2] = kmeans2(subcluster)\n",
    "    dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "    dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "    [ pre_bic,post_bic ] = computeBIC(list(cluster_concern),subcluster)\n",
    "    if post_bic<pre_bic or (len(subforest_1)<split_threshold or len(subforest_2)<split_threshold):\n",
    "        cluster_static.append(list(cluster_concern))\n",
    "        centroid_final.append(centroid_concern)\n",
    "        print('settle ',len(cluster_concern))\n",
    "    else:\n",
    "        cluster_dynamic.extend(subcluster)\n",
    "        print('split ',len(subcluster[0]),len(subcluster[1]))\n",
    "        \n",
    "print(len(cluster_static))\n",
    "computeMetrics(cluster_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[253, 11, 123, 39, 11, 11, 21, 17]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in cluster_static]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'FTCTree Distance Distribution')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.distplot(list(dist_concern.values()),bins=50)\n",
    "plt.xlabel('distance')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('FTCTree Distance Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = TreeNode()\n",
    "intersectTreeOfCusotomer(c,r1,t1)\n",
    "c.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### test case 1\n",
    "r1 = TreeNode(nodeType='root')\n",
    "r11=TreeNode(nodeType='innode',nodeClass='Food',freq=2,level=1,parent=r1)\n",
    "r1.att_childs.append(r11)\n",
    "r12=TreeNode(nodeType='innode',nodeClass='Clothes',freq=1,level=1,parent=r1)\n",
    "r1.att_childs.append(r12)\n",
    "\n",
    "r21=TreeNode(nodeType='innode',nodeClass='Drink',freq=2,level=2,parent=r11)\n",
    "r11.att_childs.append(r21)\n",
    "r22=TreeNode(nodeType='innode',nodeClass='Children Clothes',freq=1,level=2,parent=r12)\n",
    "r12.att_childs.append(r22)\n",
    "\n",
    "r31=TreeNode(nodeType='innode',nodeClass='Tea',freq=2,level=3,parent=r21)\n",
    "r21.att_childs.append(r31)\n",
    "\n",
    "r41=TreeNode(nodeType='innode',nodeClass='Black Tea',freq=1,level=4,parent=r31)\n",
    "r31.att_childs.append(r41)\n",
    "r42=TreeNode(nodeType='innode',nodeClass='Green Tea',freq=1,level=4,parent=r31)\n",
    "r31.att_childs.append(r42)\n",
    "\n",
    "\n",
    "\n",
    "t1 = TreeNode(nodeType='root')\n",
    "t11=TreeNode(nodeType='innode',nodeClass='Food',freq=2,level=1,parent=t1)\n",
    "t1.att_childs.append(t11)\n",
    "t12=TreeNode(nodeType='innode',nodeClass='Electronics',freq=1,level=1,parent=t1)\n",
    "t1.att_childs.append(t12)\n",
    "\n",
    "t21=TreeNode(nodeType='innode',nodeClass='Drink',freq=2,level=2,parent=t11)\n",
    "t11.att_childs.append(t21)\n",
    "\n",
    "t31=TreeNode(nodeType='innode',nodeClass='Tea',freq=1,level=3,parent=t21)\n",
    "t21.att_childs.append(t31)\n",
    "t32=TreeNode(nodeType='innode',nodeClass='Juice',freq=1,level=3,parent=t21)\n",
    "t21.att_childs.append(t32)\n",
    "\n",
    "t41=TreeNode(nodeType='innode',nodeClass='Black Tea',freq=1,level=4,parent=r31)\n",
    "t31.att_childs.append(t41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TreeNode()\n",
    "unionTreeOfCusotomer(a,r1,t1)\n",
    "print()\n",
    "b = TreeNode()\n",
    "intersectTreeOfCusotomer(b,r1,t1)\n",
    "dist_ir_ur(r1,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.display()\n",
    "b.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '15', 'att_level': 1, 'att_tm': '20160730', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '151', 'att_level': 2, 'att_tm': '20160730', 'parent': '15'}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '1512', 'att_level': 3, 'att_tm': '20160730', 'parent': '151'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '15120', 'att_level': 4, 'att_tm': '20160730', 'parent': '1512'}\n",
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '11', 'att_level': 1, 'att_tm': '20160501', 'parent': ''}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '115', 'att_level': 2, 'att_tm': '20160501', 'parent': '11'}\n",
      "{'nodetype': 'root', 'att_childs': 0, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'root', 'att_childs': 2, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '15', 'att_level': 1, 'att_tm': '20160730', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '11', 'att_level': 1, 'att_tm': '20160501', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '151', 'att_level': 2, 'att_tm': '20160730', 'parent': '15'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '115', 'att_level': 2, 'att_tm': '20160501', 'parent': '11'}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '1512', 'att_level': 3, 'att_tm': '20160730', 'parent': '151'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '15120', 'att_level': 4, 'att_tm': '20160730', 'parent': '1512'}\n"
     ]
    }
   ],
   "source": [
    "item = new_df.iloc[:2]\n",
    "a = createTreeBySingleTrans(item.iloc[0])['root']\n",
    "b = createTreeBySingleTrans(item.iloc[1])['root']\n",
    "new_df.head(2)\n",
    "a.display()\n",
    "b.display()\n",
    "i = TreeNode()\n",
    "intersectTreeOfCusotomer(i,a,b)\n",
    "i.display()\n",
    "u = TreeNode()\n",
    "unionTreeOfCusotomer(u,a,b)\n",
    "u.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list(dist_concern.values())\n",
    "r = sorted(r)\n",
    "sns.distplot(r,bins=200)\n",
    "r1 = list(dist_1.values())\n",
    "r1 = sorted(r1)\n",
    "r2 = list(dist_2.values())\n",
    "r2 = sorted(r2)\n",
    "sns.distplot(r1,bins=100)\n",
    "sns.distplot(r2,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
