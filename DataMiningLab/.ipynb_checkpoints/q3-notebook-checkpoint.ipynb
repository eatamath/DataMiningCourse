{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTree.py init\n",
      "columns {'uid': 'uid', 'tran_time': 'sldatime', 'gender_age': 'cmrid', 'vipno': 'vipno', 'itemno': 'pluno', 'amount': 'amt', 'quantity': 'qty', 'brandno': 'bndno', 'class1': 'class1', 'class2': 'class2', 'class3': 'class3', 'class4': 'class4', 'class5': 'class5'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import *\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neighbors import *\n",
    "from collections import *\n",
    "from pyclust import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.cluster import KMeans\n",
    "from module.EKmeans import *\n",
    "from module.CTree import *\n",
    "import datetime\n",
    "from collections import *\n",
    "import copy\n",
    "\n",
    "DATA_PATH = './trade_new.csv'\n",
    "\n",
    "_col = {\n",
    "    'uid':'uid',\n",
    "    'tran_time':'sldatime', #\n",
    "    'gender_age':'cmrid',\n",
    "    'vipno':'vipno', #\n",
    "    'itemno':'pluno', #\n",
    "    'amount':'amt', #\n",
    "    'quantity':'qty', #\n",
    "    'brandno':'bndno', #\n",
    "}\n",
    "\n",
    "_col_class = {\n",
    "    'class1':'class1',\n",
    "    'class2':'class2',\n",
    "    'class3':'class3',\n",
    "    'class4':'class4',\n",
    "    'class5':'class5',\n",
    "}\n",
    "\n",
    "_col2 ={**_col,**_col_class}\n",
    "\n",
    "print('columns',_col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[_col.values()]\n",
    "new_df = pd.DataFrame([],columns=_col2.values())\n",
    "\n",
    "\n",
    "category = df[_col2['itemno']].values.astype('str')\n",
    "category = np.array(list(map(lambda x:np.array([x[:2],x[:3],x[:4],x[:5],x[5:]]),category)))\n",
    "category = pd.DataFrame(category,columns=_col_class.values())\n",
    "if (category.index.start == df.index.start) and \\\n",
    "    (category.index.stop == df.index.stop):\n",
    "    new_df = df.join(category)\n",
    "\n",
    "df_amount_sum = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2'],_col2['class3'],_col2['class4']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum3 = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2'],_col2['class3']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum2 = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum1 = new_df.groupby([_col2['vipno'],_col2['class1']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount = [df_amount_sum1, df_amount_sum2, df_amount_sum3, df_amount_sum]\n",
    "del df\n",
    "# df_amount_sum.to_csv('./result/a1-amount_sum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将时间转化为 time level 1-4\n",
    "def processTimeLevel(new_df):\n",
    "    global _col2\n",
    "    _col2.update({\n",
    "        'tran_time_level':'tran_time_level',\n",
    "        'tran_date':'tran_date'\n",
    "    })\n",
    "    \n",
    "    tran_time = new_df[ _col2['tran_time'] ]\n",
    "    tran_time = list(map(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').timestamp(),tran_time))\n",
    "    new_df[ _col2['tran_time'] ] = tran_time\n",
    "    \n",
    "    tran_date = list( map(lambda x:datetime.datetime.strftime(datetime.datetime.fromtimestamp(x),'%Y%m%d'),tran_time) ) ### to y-m-d\n",
    "    new_df[ _col2['tran_date'] ] = tran_date\n",
    "    \n",
    "    df_temp = new_df[ [_col2['vipno'], _col2['tran_date']] ]\n",
    "    q = max(df_temp[ _col2['tran_date'] ])\n",
    "    df_temp = {row['vipno']:q for idx,row in df_temp.iterrows()}\n",
    "    tran_time_level = []\n",
    "    for idx,row in new_df.iterrows():\n",
    "        latest_date = q\n",
    "        latest_date = datetime.datetime.strptime(latest_date,'%Y%m%d').timestamp()\n",
    "        latest_date = datetime.datetime.fromtimestamp(latest_date)\n",
    "        time_level4 = (latest_date - datetime.timedelta(days=30)).timestamp()\n",
    "        time_level3 = (latest_date - datetime.timedelta(days=2*30)).timestamp()\n",
    "        time_level2 = (latest_date - datetime.timedelta(days=4*30)).timestamp()\n",
    "        time_levels = np.array([time_level2,time_level3,time_level4])\n",
    "        row_time = row[_col2['tran_time']]\n",
    "        tran_time_level.append( len(np.where(row_time>time_levels)[0])+1 ) ### append time level\n",
    "        \n",
    "    new_df[ _col2['tran_time_level'] ] = tran_time_level\n",
    "    return new_df\n",
    "\n",
    "\n",
    "new_df = processTimeLevel(new_df)\n",
    "new_df = new_df.sort_values(by=[_col2['vipno']]) ### sort by customer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 构建交易树\n",
    "#### create single tree by one transaction row\n",
    "def createTreeBySingleTrans(row):\n",
    "    troot = TreeNode(nodeType='root')\n",
    "#     root.display()\n",
    "    vipno = row[ _col2['vipno'] ]\n",
    "    class1 = row[_col2['class1']]\n",
    "    class2 = row[_col2['class2']]\n",
    "    class3 = row[_col2['class3']]\n",
    "    class4 = row[_col2['class4']]\n",
    "    tran_date = row[_col2['tran_date']]\n",
    "    newnode = TreeNode(nodeType='innode',nodeClass=class1,level=1,freq=1,tm=tran_date,parent=troot)\n",
    "    troot.att_childs.append(newnode)\n",
    "    cur_node = troot.att_childs[0]\n",
    "    for idx,c in enumerate([class2,class3,class4],2):\n",
    "#         cur_node.out()\n",
    "        if idx==4:\n",
    "            nodeType='leaf'\n",
    "            f=0\n",
    "        else:\n",
    "            if idx==row[_col2['tran_time_level']]:\n",
    "                nodeType = 'leaf'\n",
    "                f=0\n",
    "            else:\n",
    "                f=1\n",
    "                nodeType='innode'\n",
    "        newnode = TreeNode(nodeType=nodeType,nodeClass=c,level=idx,freq=1,tm=tran_date,parent=cur_node)\n",
    "        cur_node.att_childs.append(newnode)\n",
    "        cur_node = cur_node.att_childs[0]\n",
    "        if f==0:\n",
    "            break\n",
    "    return {'vipno':vipno,'root':troot}\n",
    "    \n",
    "### 合并结点\n",
    "def mergeNode(node1,node2,parent_node,tag='union'):\n",
    "    if node1.att_class == node2.att_class and \\\n",
    "        node1.att_level == node2.att_level:\n",
    "        if 'leaf' in [node1.node_type,node2.node_type]:\n",
    "            node_type = 'innode' if tag=='union' else 'leaf'\n",
    "        else:\n",
    "            node_type = 'innode'\n",
    "#             if node1.node_type!=node2.node_type:\n",
    "#                 raise Exception('error',node1.out(),node2.out())\n",
    "        return TreeNode(nodeType=node1.node_type,\n",
    "                        nodeClass=node1.att_class,\n",
    "                        level=node1.att_level,\n",
    "                        freq=sum([node1.att_freq,node2.att_freq]),\n",
    "                        tm=str(max(int(node1.att_tm),int(node2.att_tm))),\n",
    "                        parent=parent_node)\n",
    "    else:\n",
    "        raise Exception('error',node1.out(),node2.out())\n",
    "        return\n",
    "\n",
    "\n",
    "### 查找同父结点的子结点\n",
    "def findNodeByClass(root,nodeClass,level=5):\n",
    "    res = root.get_all_nodes()\n",
    "    res.append(root)\n",
    "    res = list(filter(lambda x:x.att_class==nodeClass,res)) ### find the node\n",
    "    if len(res):\n",
    "        return res[0]\n",
    "    else:\n",
    "#         print('not found class',nodeClass)\n",
    "        raise Warning('not found class')\n",
    "        return None\n",
    "        \n",
    "\n",
    "### 并集树\n",
    "def unionTreeOfCusotomer(root,root1,root2,vipno=False):\n",
    "    q = [x for x in root1.att_childs]\n",
    "    q.extend([x for x in root2.att_childs])\n",
    "    counter = Counter(list(map(lambda x:x.att_class,q)))\n",
    "    inter = list(filter(lambda x:counter[x]>1,counter))\n",
    "    noninter = list(filter(lambda x:counter[x]==1,counter))\n",
    "    while len(q):\n",
    "        nn = q.pop(0)\n",
    "        if nn.att_class in inter:\n",
    "            nn2 = list(filter(lambda x:x.att_class==nn.att_class,q))[0]\n",
    "            q.remove(nn2)\n",
    "            newnode = mergeNode(nn,nn2,root)\n",
    "            root.att_childs.append(newnode)\n",
    "            unionTreeOfCusotomer(newnode,nn,nn2)\n",
    "        else:\n",
    "            newnode = TreeNode(nn.node_type,nn.att_class,[],nn.att_freq,nn.att_level,nn.att_tm,root)\n",
    "            nn.copy(nn,newnode)\n",
    "            root.att_childs.append(newnode)\n",
    "         \n",
    "    return \n",
    "\n",
    "### 交集树\n",
    "def intersectTreeOfCusotomer(root,root1,root2,vipno=False):\n",
    "    q = [x for x in root1.att_childs]\n",
    "    q.extend([x for x in root2.att_childs])\n",
    "    counter = Counter(list(map(lambda x:x.att_class,q)))\n",
    "    inter = list(filter(lambda x:counter[x]>1,counter))\n",
    "    noninter = list(filter(lambda x:counter[x]==1,counter))\n",
    "    while len(q):\n",
    "        nn = q.pop(0)\n",
    "        if nn.att_class in inter:\n",
    "            nn2 = list(filter(lambda x:x.att_class==nn.att_class,q))[0]\n",
    "            q.remove(nn2)\n",
    "            newnode = mergeNode(nn,nn2,root)\n",
    "            root.att_childs.append(newnode)\n",
    "            intersectTreeOfCusotomer(newnode,nn,nn2)\n",
    "         \n",
    "    return \n",
    "\n",
    "### 对每个用户构建交易树\n",
    "def buildTreeOfCustomers(df,all_customers):\n",
    "    global _col2\n",
    "    customer_forest = {c:TreeNode(nodeType='root') for c in all_customers}\n",
    "    for idx,row in df.iterrows():\n",
    "        cust = row[ _col2['vipno'] ]\n",
    "        subtree = createTreeBySingleTrans(row)['root']\n",
    "        temp_root = TreeNode()\n",
    "        unionTreeOfCusotomer(temp_root,customer_forest[cust],subtree)\n",
    "        customer_forest[cust] = temp_root\n",
    "    return customer_forest\n",
    "\n",
    "### 相似度 结点\n",
    "def sim_v_ur(v,ur):\n",
    "    try:\n",
    "        parentnode_ur = ur.find_class(v.att_parent.att_class)\n",
    "        if parentnode_ur is None:\n",
    "            parentnode_ur = findNodeByClass(root=ur,nodeClass=v.att_parent.att_class)\n",
    "    except Warning as e:\n",
    "        print('not found ',v.att_parent.att_class)\n",
    "        return 0\n",
    "    freq_ur = [x.att_freq for x in parentnode_ur.att_childs]\n",
    "    try:\n",
    "        res = float(v.att_freq/np.sum(freq_ur))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "\n",
    "### 相似度 层\n",
    "def sim_vl_ur(vl,ur):\n",
    "    if len(vl)==0:\n",
    "        return 0\n",
    "    try:\n",
    "        s = list(map(lambda x:sim_v_ur(x,ur),vl))\n",
    "        return np.mean(s)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "\n",
    "### 相似度 树\n",
    "def dist_ir_ur(ir,ur):\n",
    "    utree = TreeNode()\n",
    "    unionTreeOfCusotomer(utree,ir,ur)\n",
    "    itree = TreeNode()\n",
    "    intersectTreeOfCusotomer(itree,ir,ur)\n",
    "    ir = itree\n",
    "    ur = utree\n",
    "    nodes_ir = ir.get_all_nodes()\n",
    "    if len(nodes_ir)==0:\n",
    "        return 1\n",
    "    H = max(set(list(map(lambda x:x.att_level,nodes_ir))))\n",
    "    s = 0\n",
    "    for i in range(1,H+1):\n",
    "        w = i/np.sum(range(1,H+1))\n",
    "        vl = list(filter(lambda x:x.att_level==i,nodes_ir))\n",
    "        s += w*sim_vl_ur(vl,ur)\n",
    "    return 1-s\n",
    "\n",
    "### 用 freq 更新树\n",
    "def updateTreeByFrequence(root,freq):\n",
    "    nodes = [x for x in root.att_childs]\n",
    "    for nn in nodes:\n",
    "        if nn.att_freq<freq:\n",
    "            root.att_childs.remove(nn)\n",
    "            nn.att_parent = None\n",
    "        else:\n",
    "            updateTreeByFrequence(nn,freq)\n",
    "    return\n",
    "\n",
    "### 中心树\n",
    "def getClusterCentroid(forest_customer):\n",
    "    global customers\n",
    "    centroid = TreeNode(nodeType='root')\n",
    "    for tr in forest_customer:\n",
    "        temp_root = TreeNode()\n",
    "        unionTreeOfCusotomer(temp_root,centroid,forest_customer[tr])\n",
    "        centroid = temp_root\n",
    "    \n",
    "    current_freq = 1\n",
    "    mindist = 1e10\n",
    "    freq_step = centroid.get_avg_freq()\n",
    "    freq_end = centroid.get_max_freq()\n",
    "    centroid_record = centroid\n",
    "    size_average = np.mean(list(map(lambda x:forest_customer[x].get_node_size(),forest_customer)))\n",
    "    print('freq ',freq_step,freq_end)\n",
    "    while current_freq<freq_end:\n",
    "        updateTreeByFrequence(centroid,current_freq)\n",
    "        dist = sum([dist_ir_ur(forest_customer[c],centroid) for c in forest_customer])\n",
    "        if dist<mindist:\n",
    "            mindist = dist\n",
    "            centroid_record = TreeNode()\n",
    "            centroid.copy(centroid,centroid_record)\n",
    "        if centroid.get_node_size()<size_average:\n",
    "            print('size quit')\n",
    "            break\n",
    "        current_freq += freq_step\n",
    "    return centroid_record\n",
    "\n",
    "    \n",
    "### 主程序\n",
    "def clusterMain():\n",
    "    ### 计算最远的对\n",
    "    ### get distant pair\n",
    "    def distantPair(topK_key,forest_concern):\n",
    "        max_dist = 0\n",
    "        max_pair = None\n",
    "        for i in topK_key:\n",
    "            for j in topK_key:\n",
    "                if j>i:\n",
    "                    dist = dist_ir_ur(forest_concern[i],forest_concern[j])\n",
    "                    if dist>max_dist:\n",
    "                        max_dist = dist\n",
    "                        max_pair = (i,j)\n",
    "        return [max_dist,max_pair]\n",
    "\n",
    "    ### 更新 cluster label\n",
    "    ### recluster forest_concern\n",
    "    def recluster():\n",
    "        print('recluster')\n",
    "        subcluster = [[],[]]\n",
    "        for c in forest_concern:\n",
    "            current_tree = forest_concern[c]\n",
    "            [dist1,dist2] = [\n",
    "                dist_ir_ur(current_tree,forest_concern[max_pair[0]]),\n",
    "                dist_ir_ur(current_tree,forest_concern[max_pair[1]])\n",
    "            ]\n",
    "            if dist1<dist2:\n",
    "                subcluster[0].append(c)\n",
    "            else:\n",
    "                subcluster[1].append(c)\n",
    "        return subcluster\n",
    "\n",
    "    ### 计算BIC\n",
    "    ### precluster [] ; postcluster [[]]\n",
    "    def computeBIC(precluster,postcluster):\n",
    "        print('compute BIC')\n",
    "        N = len(precluster)\n",
    "    #     D = set([])\n",
    "    #     [D.union(customer_buy[x]) for x in precluster]\n",
    "    #     D = len(D)\n",
    "        D = sum([customer_buy_count[x] for x in precluster])\n",
    "        pre_coff_1 = (N-1)\n",
    "        pre_sigma_s = 1.0/pre_coff_1 * np.sum(np.power(list(dist_concern.values()),2))\n",
    "        pre_likelihood = -N/2*np.log(2*np.pi) - N*D/2*np.log(pre_sigma_s) - pre_coff_1/2\n",
    "        pre_bic = pre_likelihood - 1*(D+1)/2*np.log(1)\n",
    "\n",
    "        N_i = np.array([len(postcluster[0]), len(postcluster[1])])\n",
    "    #     D_i = np.array([\n",
    "    #         sum([customer_buy_count[x] for x in postcluster[0]]),\n",
    "    #         sum([customer_buy_count[x] for x in postcluster[1]])\n",
    "    #     ])\n",
    "        post_coff_1 = N_i - 2\n",
    "        post_sigma_s = 1.0/post_coff_1 * np.array([ \n",
    "            np.sum( np.power(list( dist_1.values() ),2) ), \n",
    "            np.sum( np.power(list( dist_2.values() ),2) )\n",
    "        ])\n",
    "        post_likelihood = N_i*np.log(N_i) - N_i*np.log(N) - N_i/2*np.log(2*np.pi) - N_i*D/2*np.log(post_sigma_s) - post_coff_1/2\n",
    "        post_likelihood = np.sum(post_likelihood)\n",
    "        post_bic = post_likelihood - 2*(D+1)/2*np.log(2)\n",
    "\n",
    "    #     print('bic ',pre_bic,post_bic)\n",
    "        return pre_bic,post_bic\n",
    "\n",
    "    ### 计算评分\n",
    "    ### compute metrics and scores\n",
    "    def computeMetrics(cluster_final):\n",
    "        print('compute metrics')\n",
    "    #     cluster_final = cluster_static\n",
    "        mapping = {x:i for i,x in enumerate(customers,0)} ### customer:idx\n",
    "        d = np.array([[0.0 for i in range(len(customers))] for j in range(len(customers))])\n",
    "        ### 计算距离矩阵\n",
    "        for i,x in enumerate(customers,0):\n",
    "            for j,y in enumerate(customers,0):\n",
    "                if j>=i:\n",
    "                    d[ mapping[x] ][ mapping[y] ] = dist_ir_ur(forest_customer[x],forest_customer[y])\n",
    "                    d[ mapping[y] ][ mapping[x] ] = d[ mapping[x] ][ mapping[y] ]\n",
    "\n",
    "        sc = 0\n",
    "        B = np.array([0.0 for i in range(len(customers))])\n",
    "        A = np.array([0.0 for j in range(len(customers))])\n",
    "        cust_all = set(customers)\n",
    "        for m,cl in enumerate(cluster_final,0):\n",
    "            cust_cl = set(cl)\n",
    "            for p in cl:\n",
    "                same = cust_cl - set([p])\n",
    "                #### find nearest neighbor centroid\n",
    "                record_nearest = None\n",
    "                record_mindist = 100\n",
    "                for n,ct in enumerate(centroid_final,0):\n",
    "                    if m!=n:\n",
    "                        temp_dist = dist_ir_ur(forest_customer[p],ct)\n",
    "                        if temp_dist<record_mindist:\n",
    "                            record_mindist = temp_dist\n",
    "                            record_nearest = n\n",
    "\n",
    "                other = cluster_final[n]\n",
    "                A[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[s] ] for s in same])\n",
    "                B[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[o] ] for o in other])\n",
    "        sc = np.mean([(B[i]-A[i])/np.max([A[i],B[i]]) for i in range(len(customers))])\n",
    "        print('sc ',sc)\n",
    "\n",
    "        cp = np.mean([ \n",
    "            np.mean( list(map(lambda x:dist_ir_ur(forest_customer[x],centroid_final[i]),cl)) ) \n",
    "            for i,cl in enumerate(cluster_final,0) \n",
    "        ])\n",
    "        print('cp ',cp)\n",
    "\n",
    "        return sc,cp\n",
    "\n",
    "    ### 2-means聚类\n",
    "    ### compute 2-means\n",
    "    def kmeans2(subcluster):\n",
    "        print('2-means')\n",
    "        #### update recluster result\n",
    "        subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "        subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "        centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "        centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "        #### get all points in subcluster\n",
    "        all_points = copy.deepcopy(subcluster[0])\n",
    "        all_points.extend(subcluster[1])\n",
    "        _record_iter = 0\n",
    "        _record_cluster = []\n",
    "        new_subcluster = []\n",
    "        while 1:\n",
    "            _record_cluster = copy.deepcopy(new_subcluster)\n",
    "            #### re-distribute according centroid12\n",
    "            new_subcluster = [[],[]]\n",
    "            for x in all_points:\n",
    "                dist1 = dist_ir_ur(forest_customer[x],centroid_1)\n",
    "                dist2 = dist_ir_ur(forest_customer[x],centroid_2)\n",
    "                if dist1<dist2:\n",
    "                    new_subcluster[0].append(x)\n",
    "                else:\n",
    "                    new_subcluster[1].append(x)\n",
    "            #### updating centroid12\n",
    "            subforest_1 = { x:forest_customer[x] for x in new_subcluster[0] }\n",
    "            subforest_2 = { x:forest_customer[x] for x in new_subcluster[1] }\n",
    "            centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "            centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "            print('original cluster ',len(subcluster[0]),len(subcluster[1]))\n",
    "            print('new cluster ',len(new_subcluster[0]),len(new_subcluster[1]))\n",
    "            #### condition\n",
    "            if ( _record_iter>1 and abs(len(new_subcluster[0]) - len(_record_cluster[0])) < int(0.05*len(all_points)) ) \\\n",
    "                or _record_iter>10:\n",
    "                break\n",
    "            _record_iter += 1\n",
    "        return new_subcluster,subforest_1,subforest_2,centroid_1,centroid_2\n",
    "\n",
    "    top_ratio = 0.7\n",
    "    topK_max = 80\n",
    "    split_threshold = 10\n",
    "    method = 'random'\n",
    "    global new_df\n",
    "    customer_buy_count = new_df.groupby(by=[_col2['vipno']]).count()['class4'].to_dict() ### { customer:buy_count }\n",
    "    customers = list( set(new_df[_col2['vipno']]) ) ### all customers : list\n",
    "    customer_buy = {x:set([]) for x in customers}\n",
    "    [customer_buy[ row[_col2['vipno']] ].add(row[_col2['class4']]) for idx,row in new_df.iterrows()] ### { customer:buy_items }\n",
    "    forest_customer = buildTreeOfCustomers(new_df,customers) ### customer tree {vipno:root}\n",
    "    [forest_customer[x].speed() for x in forest_customer] ### speed up searching\n",
    "    cluster_dynamic = [[x for x in customers]]\n",
    "    cluster_static = []\n",
    "    centroid_final = []\n",
    "    while len(cluster_dynamic):\n",
    "        cluster_concern = cluster_dynamic.pop(0)\n",
    "        cluster_concern = set(cluster_concern)\n",
    "        forest_concern = list(filter(lambda x:x in cluster_concern,forest_customer))\n",
    "        forest_concern = { x:forest_customer[x] for x in forest_concern }\n",
    "        centroid_concern = getClusterCentroid(forest_concern) ### centoid tree of interest\n",
    "        topK = min( [ topK_max,max([2,top_ratio*len(forest_concern)]) ] )\n",
    "        topK = int(topK)\n",
    "        dist_concern = { x:dist_ir_ur(forest_concern[x],centroid_concern) for x in forest_concern } ### dist of @forest_concern & @centroid_concern\n",
    "        if method == 'random':\n",
    "            topK_key = np.array(list(forest_concern.keys()))[np.random.permutation(len(forest_concern))[:topK]]\n",
    "        if method == 'fixed':\n",
    "            topK_key = sorted(dist_concern,key=lambda x:dist_concern[x],reverse=True)[:topK]\n",
    "        [max_dist,max_pair] = distantPair(topK_key,forest_concern) ### find most distant pair\n",
    "        subcluster = recluster()\n",
    "        [forest_concern[x].speed() for x in forest_concern] ### speed up searching\n",
    "    #         subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "    #         subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "    #         centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "    #         centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "    #         dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "    #         dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "    #     break\n",
    "\n",
    "    #     if len(subcluster[0])<split_threshold or len(subcluster[1])<split_threshold:\n",
    "    #         cluster_static.append(list(cluster_concern))\n",
    "    #         centroid_final.append(centroid_concern)\n",
    "    #         print('settle ',len(cluster_concern))\n",
    "    #         continue\n",
    "        [subcluster,subforest_1,subforest_2,centroid_1,centroid_2] = kmeans2(subcluster)\n",
    "        dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "        dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "        [ pre_bic,post_bic ] = computeBIC(list(cluster_concern),subcluster)\n",
    "        if post_bic<pre_bic or (len(subforest_1)<split_threshold or len(subforest_2)<split_threshold):\n",
    "            cluster_static.append(list(cluster_concern))\n",
    "            centroid_final.append(centroid_concern)\n",
    "            print('settle ',len(cluster_concern))\n",
    "        else:\n",
    "            cluster_dynamic.extend(subcluster)\n",
    "            print('split ',len(subcluster[0]),len(subcluster[1]))\n",
    "\n",
    "    print(len(cluster_static))\n",
    "#     computeMetrics(cluster_static)\n",
    "    return computeMetrics(cluster_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterMain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试用例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：交集树和并集树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test case 1\n",
    "r1 = TreeNode(nodeType='root')\n",
    "r11=TreeNode(nodeType='innode',nodeClass='Food',freq=2,level=1,parent=r1)\n",
    "r1.att_childs.append(r11)\n",
    "r12=TreeNode(nodeType='innode',nodeClass='Clothes',freq=1,level=1,parent=r1)\n",
    "r1.att_childs.append(r12)\n",
    "\n",
    "r21=TreeNode(nodeType='innode',nodeClass='Drink',freq=2,level=2,parent=r11)\n",
    "r11.att_childs.append(r21)\n",
    "r22=TreeNode(nodeType='innode',nodeClass='Children Clothes',freq=1,level=2,parent=r12)\n",
    "r12.att_childs.append(r22)\n",
    "\n",
    "r31=TreeNode(nodeType='innode',nodeClass='Tea',freq=2,level=3,parent=r21)\n",
    "r21.att_childs.append(r31)\n",
    "\n",
    "r41=TreeNode(nodeType='innode',nodeClass='Black Tea',freq=1,level=4,parent=r31)\n",
    "r31.att_childs.append(r41)\n",
    "r42=TreeNode(nodeType='innode',nodeClass='Green Tea',freq=1,level=4,parent=r31)\n",
    "r31.att_childs.append(r42)\n",
    "\n",
    "\n",
    "\n",
    "t1 = TreeNode(nodeType='root')\n",
    "t11=TreeNode(nodeType='innode',nodeClass='Food',freq=2,level=1,parent=t1)\n",
    "t1.att_childs.append(t11)\n",
    "t12=TreeNode(nodeType='innode',nodeClass='Electronics',freq=1,level=1,parent=t1)\n",
    "t1.att_childs.append(t12)\n",
    "\n",
    "t21=TreeNode(nodeType='innode',nodeClass='Drink',freq=2,level=2,parent=t11)\n",
    "t11.att_childs.append(t21)\n",
    "\n",
    "t31=TreeNode(nodeType='innode',nodeClass='Tea',freq=1,level=3,parent=t21)\n",
    "t21.att_childs.append(t31)\n",
    "t32=TreeNode(nodeType='innode',nodeClass='Juice',freq=1,level=3,parent=t21)\n",
    "t21.att_childs.append(t32)\n",
    "\n",
    "t41=TreeNode(nodeType='innode',nodeClass='Black Tea',freq=1,level=4,parent=r31)\n",
    "t31.att_childs.append(t41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union tree\n",
      "{'nodetype': 'root', 'att_childs': 3, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 4, 'att_class': 'Food', 'att_level': 1, 'att_tm': '0', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': 'Clothes', 'att_level': 1, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 1, 'att_class': 'Electronics', 'att_level': 1, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 2, 'att_freq': 4, 'att_class': 'Drink', 'att_level': 2, 'att_tm': '0', 'parent': 'Food'}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 1, 'att_class': 'Children Clothes', 'att_level': 2, 'att_tm': 0, 'parent': 'Clothes'}\n",
      "{'nodetype': 'innode', 'att_childs': 2, 'att_freq': 3, 'att_class': 'Tea', 'att_level': 3, 'att_tm': '0', 'parent': 'Drink'}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 1, 'att_class': 'Juice', 'att_level': 3, 'att_tm': 0, 'parent': 'Drink'}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 2, 'att_class': 'Black Tea', 'att_level': 4, 'att_tm': '0', 'parent': 'Tea'}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 1, 'att_class': 'Green Tea', 'att_level': 4, 'att_tm': 0, 'parent': 'Tea'}\n",
      "\n",
      "\n",
      "intersection tree\n",
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 4, 'att_class': 'Food', 'att_level': 1, 'att_tm': '0', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 4, 'att_class': 'Drink', 'att_level': 2, 'att_tm': '0', 'parent': 'Food'}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 3, 'att_class': 'Tea', 'att_level': 3, 'att_tm': '0', 'parent': 'Drink'}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 2, 'att_class': 'Black Tea', 'att_level': 4, 'att_tm': '0', 'parent': 'Tea'}\n",
      "\n",
      "\n",
      "distance of r1 t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2416666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = TreeNode()\n",
    "print('union tree')\n",
    "unionTreeOfCusotomer(a,r1,t1)\n",
    "a.display()\n",
    "print('\\n')\n",
    "b = TreeNode()\n",
    "print('intersection tree')\n",
    "intersectTreeOfCusotomer(b,r1,t1)\n",
    "b.display()\n",
    "print('\\n')\n",
    "print('distance of r1 t1')\n",
    "dist_ir_ur(r1,t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：中心树的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq  2.0 4\n",
      "size quit\n",
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 4, 'att_class': 'Food', 'att_level': 1, 'att_tm': '0', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 4, 'att_class': 'Drink', 'att_level': 2, 'att_tm': '0', 'parent': 'Food'}\n",
      "{'nodetype': 'innode', 'att_childs': 0, 'att_freq': 3, 'att_class': 'Tea', 'att_level': 3, 'att_tm': '0', 'parent': 'Drink'}\n"
     ]
    }
   ],
   "source": [
    "getClusterCentroid({1:r1,2:t1}).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：交易树的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '15', 'att_level': 1, 'att_tm': '20160730', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '151', 'att_level': 2, 'att_tm': '20160730', 'parent': '15'}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '1512', 'att_level': 3, 'att_tm': '20160730', 'parent': '151'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '15120', 'att_level': 4, 'att_tm': '20160730', 'parent': '1512'}\n",
      "\n",
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '11', 'att_level': 1, 'att_tm': '20160501', 'parent': ''}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '115', 'att_level': 2, 'att_tm': '20160501', 'parent': '11'}\n",
      "\n",
      "{'nodetype': 'root', 'att_childs': 0, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "\n",
      "{'nodetype': 'root', 'att_childs': 2, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '15', 'att_level': 1, 'att_tm': '20160730', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '11', 'att_level': 1, 'att_tm': '20160501', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '151', 'att_level': 2, 'att_tm': '20160730', 'parent': '15'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '115', 'att_level': 2, 'att_tm': '20160501', 'parent': '11'}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '1512', 'att_level': 3, 'att_tm': '20160730', 'parent': '151'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '15120', 'att_level': 4, 'att_tm': '20160730', 'parent': '1512'}\n"
     ]
    }
   ],
   "source": [
    "item = new_df.iloc[:2]\n",
    "a = createTreeBySingleTrans(item.iloc[0])['root']\n",
    "b = createTreeBySingleTrans(item.iloc[1])['root']\n",
    "new_df.head(2)\n",
    "a.display()\n",
    "print('')\n",
    "b.display()\n",
    "i = TreeNode()\n",
    "intersectTreeOfCusotomer(i,a,b)\n",
    "print('')\n",
    "i.display()\n",
    "u = TreeNode()\n",
    "unionTreeOfCusotomer(u,a,b)\n",
    "print('')\n",
    "u.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
