{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTree.py init\n",
      "columns {'uid': 'uid', 'tran_time': 'sldatime', 'gender_age': 'cmrid', 'vipno': 'vipno', 'itemno': 'pluno', 'amount': 'amt', 'quantity': 'qty', 'brandno': 'bndno', 'class1': 'class1', 'class2': 'class2', 'class3': 'class3', 'class4': 'class4', 'class5': 'class5'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import *\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neighbors import *\n",
    "from collections import *\n",
    "from pyclust import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.cluster import KMeans\n",
    "from module.EKmeans import *\n",
    "from module.CTree import *\n",
    "import datetime\n",
    "from collections import *\n",
    "\n",
    "DATA_PATH = './trade_new.csv'\n",
    "\n",
    "_col = {\n",
    "    'uid':'uid',\n",
    "    'tran_time':'sldatime', #\n",
    "    'gender_age':'cmrid',\n",
    "    'vipno':'vipno', #\n",
    "    'itemno':'pluno', #\n",
    "    'amount':'amt', #\n",
    "    'quantity':'qty', #\n",
    "    'brandno':'bndno', #\n",
    "}\n",
    "\n",
    "_col_class = {\n",
    "    'class1':'class1',\n",
    "    'class2':'class2',\n",
    "    'class3':'class3',\n",
    "    'class4':'class4',\n",
    "    'class5':'class5',\n",
    "}\n",
    "\n",
    "_col2 ={**_col,**_col_class}\n",
    "\n",
    "print('columns',_col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[_col.values()]\n",
    "new_df = pd.DataFrame([],columns=_col2.values())\n",
    "\n",
    "\n",
    "category = df[_col2['itemno']].values.astype('str')\n",
    "category = np.array(list(map(lambda x:np.array([x[:2],x[:3],x[:4],x[:5],x[5:]]),category)))\n",
    "category = pd.DataFrame(category,columns=_col_class.values())\n",
    "if (category.index.start == df.index.start) and \\\n",
    "    (category.index.stop == df.index.stop):\n",
    "    new_df = df.join(category)\n",
    "\n",
    "df_amount_sum = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2'],_col2['class3'],_col2['class4']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum3 = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2'],_col2['class3']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum2 = new_df.groupby([_col2['vipno'],_col2['class1'],_col2['class2']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount_sum1 = new_df.groupby([_col2['vipno'],_col2['class1']],as_index=False).agg({\n",
    "    _col2['amount']:sum\n",
    "})\n",
    "df_amount = [df_amount_sum1, df_amount_sum2, df_amount_sum3, df_amount_sum]\n",
    "del df\n",
    "# df_amount_sum.to_csv('./result/a1-amount_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "set_vipno = set(df_amount_sum[_col2['vipno']])\n",
    "mapping_index_v = {i:idx for (idx,i) in zip(range(len(set_vipno)),set_vipno)}\n",
    "\n",
    "\n",
    "def aggByUser(category='class4'):\n",
    "    global set_vipno,df_amount,_col2\n",
    "    map_single = {v:{} for v in set_vipno}\n",
    "    df_temp = df_amount[ int(category[-1])-1 ]\n",
    "    for v in set_vipno:\n",
    "        lst_v = df_temp.loc[ df_temp[_col2['vipno']]==v ]\n",
    "        for idx,row in lst_v.iterrows():\n",
    "            map_single[v][ row[ _col2[ category ] ] ] = row[ _col2['amount'] ]\n",
    "    return map_single\n",
    "\n",
    "\n",
    "def computeUserFeatureOfClass(category='class4'):\n",
    "    global df_amount,mapping_index_v,_col2\n",
    "    set_class_i = set(new_df[_col2[ category ]])\n",
    "    mapping_index_class_i = {i:idx for (idx,i) in zip(range(len(set_class_i)),set_class_i)}\n",
    "    mat_userFeature = np.array([[0.0 for i in range(len(set_class_i))] for j in range(len(set_vipno))])\n",
    "    for idx,r in df_amount[ int(category[-1])-1 ].iterrows():\n",
    "        mat_userFeature[ mapping_index_v[ r[ _col2['vipno'] ] ] ][ mapping_index_class_i[ r[ _col2[category] ] ] ] = r[ _col2['amount'] ]\n",
    "    return mat_userFeature\n",
    "\n",
    "\n",
    "def computeJaccardDistance(a,b):\n",
    "    return 1-np.sum(np.min([a,b],0))/np.sum(np.max([a,b],0))\n",
    "\n",
    "\n",
    "def computeJaccardMatrix(mat_userFeature):\n",
    "    global set_vipno,map_single,mapping_index_v,D\n",
    "    mat_jaccard = np.array([[0 for i in range(len(set_vipno))] for j in range(len(set_vipno))]).astype('float')\n",
    "    for v1 in set_vipno:\n",
    "        for v2 in set_vipno:\n",
    "            jaccard_pairwise_dist = compute_distance(a=mat_userFeature[mapping_index_v[v1]],b=mat_userFeature[mapping_index_v[v2]],D=D,metric='cos')\n",
    "            mat_jaccard[mapping_index_v[v1]][mapping_index_v[v2]] = mat_jaccard[mapping_index_v[v2]][mapping_index_v[v1]] = jaccard_pairwise_dist\n",
    "    return mat_jaccard\n",
    "\n",
    "def compute_distance(a,b,D,metric='jaccard'):\n",
    "    if metric=='jaccard':\n",
    "        return computeJaccardDistance(a,b)\n",
    "    elif metric=='euclidean':\n",
    "        return norm(a-b)\n",
    "    elif metric=='cos':\n",
    "        score = [computeJaccardDistance(a[:D[0]],b[:D[0]]),\n",
    "                computeJaccardDistance(a[D[0]:D[1]],b[D[0]:D[1]]),\n",
    "                computeJaccardDistance(a[D[1]:D[2]],b[D[1]:D[2]]),\n",
    "                computeJaccardDistance(a[D[2]:D[3]],b[D[2]:D[3]])]\n",
    "#             print(score)\n",
    "        return sum(score)/4\n",
    "\n",
    "class EKmeans():\n",
    "    def __init__(self,X,D,method='jaccard',n_centers=2,max_iters=1000,tol=1e-20,verbose=0):\n",
    "        self.n_centers = n_centers\n",
    "        self.max_iters = max_iters\n",
    "        self.D = D\n",
    "        self.method = method\n",
    "        self.X = X\n",
    "        self.clusters = np.array([-1 for i in range(X.shape[0])])\n",
    "        self.centers = self.X[np.random.permutation(X.shape[0])[:self.n_centers]]\n",
    "        self.pre_centers = []\n",
    "        self.debug = []\n",
    "        self.lr = 0.34\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        return\n",
    "    \n",
    "    def metrics_compactness(self):\n",
    "        s = 0.0\n",
    "        for c in range(self.n_centers):\n",
    "            idx_cluster = np.where(self.clusters==c)[0]\n",
    "            for a in self.X[ idx_cluster ]:\n",
    "                dst = compute_distance(a=a,b=self.centers[c],D=self.D,metric=self.method)\n",
    "                s += dst*1.0/len(idx_cluster)\n",
    "        return s\n",
    "                \n",
    "    def __update_centers(self,smooth=True):\n",
    "        self.pre_centers = np.array(self.centers)\n",
    "        for c in range(self.n_centers):\n",
    "            temp = self.X[ np.where(self.clusters==c)[0] ]\n",
    "            if len(temp):\n",
    "                self.centers[c] = np.array([ np.mean( temp, 0 ) ])\n",
    "#             print(self.centers,self.X[ np.where(self.clusters==c)[0] ]) ### debug\n",
    "        if smooth:\n",
    "            self.centers = (self.centers-self.pre_centers)*self.lr + self.pre_centers\n",
    "        return\n",
    "    \n",
    "    def __log(self,x):\n",
    "        if self.verbose:\n",
    "            print(x)\n",
    "        return\n",
    "    \n",
    "    def fit(self):\n",
    "        for kiter in range(self.max_iters):\n",
    "            self.__log('iteration %d'%kiter)\n",
    "            for i in range(self.X.shape[0]):\n",
    "                d_min_dist = 1e10\n",
    "                record_node = -1\n",
    "                for idx,c in zip(range(len(self.centers)),self.centers):\n",
    "                    dst = compute_distance(a=self.X[i],b=c,D=self.D,metric=self.method)\n",
    "                    if dst<d_min_dist:\n",
    "                        d_min_dist = dst\n",
    "                        record_node = idx\n",
    "                self.clusters[i] = record_node\n",
    "            self.__update_centers()\n",
    "            move_dist = np.mean(norm(self.pre_centers-self.centers,axis=1))\n",
    "            self.debug.append(move_dist)\n",
    "            if (kiter - kiter//20 *20 ==1) and move_dist<self.tol:\n",
    "                break\n",
    "            if kiter==10:\n",
    "#                 raise Exception('stop')\n",
    "                pass\n",
    "        return\n",
    "\n",
    "\n",
    "# map_single = aggByUser()\n",
    "mat_userFeature = [computeUserFeatureOfClass('class1'),\n",
    "                   computeUserFeatureOfClass('class2'),\n",
    "                   computeUserFeatureOfClass('class3'),\n",
    "                   computeUserFeatureOfClass('class4')\n",
    "                  ]\n",
    "\n",
    "D =np.cumsum(\n",
    "    [\n",
    "        mat_userFeature[0].shape[1],\n",
    "        mat_userFeature[1].shape[1],\n",
    "        mat_userFeature[2].shape[1],\n",
    "        mat_userFeature[3].shape[1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "mat_jaccard = computeJaccardMatrix(np.hstack(mat_userFeature))\n",
    "\n",
    "def KmeansCluster(n_centers,method='cos',max_iters=500):\n",
    "    global mat_userFeature,D\n",
    "    if method=='jaccard':\n",
    "        kmeans = EKmeans(mat_userFeature[-1],None,n_centers=n_centers,max_iters=max_iters)\n",
    "    elif method=='cos':\n",
    "        kmeans = EKmeans(np.hstack(mat_userFeature),D,n_centers=n_centers,max_iters=max_iters,method='cos')\n",
    "    elif method=='euclidean':\n",
    "        kmeans = EKmeans(mat_userFeature[-1],None,n_centers=n_centers,max_iters=max_iters,method='euclidean')\n",
    "    kmeans.fit()\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "clusters = kmeans.fit_predict(mat_userFeature[-1])\n",
    "silhouette_score(mat_userFeature[-1],labels=clusters)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for nn in range(2,20):\n",
    "    print('param ',nn)\n",
    "    kmeans = KmeansCluster(nn,'cos',1000)\n",
    "    sil = silhouette_score(mat_jaccard,labels=kmeans.clusters,metric='precomputed')\n",
    "    com = kmeans.metrics_compactness() \n",
    "    res.append({'sil':sil,'com':com,'nn':nn})\n",
    "\n",
    "# tsne = TSNE(n_jobs=-1,method='exact',n_components=2)\n",
    "# mat_userFeature_t = tsne.fit_transform(np.hstack(mat_userFeature))\n",
    "\n",
    "# sns.set(style=\"ticks\")\n",
    "# sns.pairplot(pd.DataFrame(mat_userFeature[:,100:110]),kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 将时间转化为 time level 1-4\n",
    "def processTimeLevel(new_df):\n",
    "    global _col2\n",
    "    _col2.update({\n",
    "        'tran_time_level':'tran_time_level',\n",
    "        'tran_date':'tran_date'\n",
    "    })\n",
    "    \n",
    "    tran_time = new_df[ _col2['tran_time'] ]\n",
    "    tran_time = list(map(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').timestamp(),tran_time))\n",
    "    new_df[ _col2['tran_time'] ] = tran_time\n",
    "    \n",
    "    tran_date = list( map(lambda x:datetime.datetime.strftime(datetime.datetime.fromtimestamp(x),'%Y%m%d'),tran_time) ) ### to y-m-d\n",
    "    new_df[ _col2['tran_date'] ] = tran_date\n",
    "    \n",
    "    df_temp = new_df[ [_col2['vipno'], _col2['tran_date']] ]\n",
    "#     df_temp = df_temp.groupby(by=['vipno']).agg({_col2['tran_date']:max}).reset_index().values\n",
    "#     df_temp = {x[0]:x[1] for x in df_temp}\n",
    "    q = max(df_temp[ _col2['tran_date'] ])\n",
    "    df_temp = {row['vipno']:q for idx,row in df_temp.iterrows()}\n",
    "#     print(set(new_df['vipno'])-set(df_temp.keys()))\n",
    "    tran_time_level = []\n",
    "    for idx,row in new_df.iterrows():\n",
    "        latest_date = q\n",
    "        latest_date = datetime.datetime.strptime(latest_date,'%Y%m%d').timestamp()\n",
    "        latest_date = datetime.datetime.fromtimestamp(latest_date)\n",
    "        time_level4 = (latest_date - datetime.timedelta(days=30)).timestamp()\n",
    "        time_level3 = (latest_date - datetime.timedelta(days=2*30)).timestamp()\n",
    "        time_level2 = (latest_date - datetime.timedelta(days=4*30)).timestamp()\n",
    "#         time_level1 = (latest_date - datetime.timedelta(days=16*30)).timestamp()\n",
    "        time_levels = np.array([time_level2,time_level3,time_level4])\n",
    "        row_time = row[_col2['tran_time']]\n",
    "        tran_time_level.append( len(np.where(row_time>time_levels)[0])+1 ) ### append time level\n",
    "        \n",
    "    new_df[ _col2['tran_time_level'] ] = tran_time_level\n",
    "    return new_df\n",
    "\n",
    "\n",
    "new_df = processTimeLevel(new_df)\n",
    "new_df = new_df.sort_values(by=[_col2['vipno']]) ### sort by customer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### create single tree by one transaction row\n",
    "def createTreeBySingleTrans(row):\n",
    "    troot = TreeNode(nodeType='root')\n",
    "#     root.display()\n",
    "    vipno = row[ _col2['vipno'] ]\n",
    "    class1 = row[_col2['class1']]\n",
    "    class2 = row[_col2['class2']]\n",
    "    class3 = row[_col2['class3']]\n",
    "    class4 = row[_col2['class4']]\n",
    "    tran_date = row[_col2['tran_date']]\n",
    "    newnode = TreeNode(nodeType='innode',nodeClass=class1,level=1,freq=1,tm=tran_date,parent=troot)\n",
    "    troot.att_childs.append(newnode)\n",
    "    cur_node = troot.att_childs[0]\n",
    "    for idx,c in enumerate([class2,class3,class4],2):\n",
    "#         cur_node.out()\n",
    "        if idx==4:\n",
    "            nodeType='leaf'\n",
    "            f=0\n",
    "        else:\n",
    "            if idx==row[_col2['tran_time_level']]:\n",
    "                nodeType = 'leaf'\n",
    "                f=0\n",
    "            else:\n",
    "                f=1\n",
    "                nodeType='innode'\n",
    "        newnode = TreeNode(nodeType=nodeType,nodeClass=c,level=idx,freq=1,tm=tran_date,parent=cur_node)\n",
    "        cur_node.att_childs.append(newnode)\n",
    "        cur_node = cur_node.att_childs[0]\n",
    "        if f==0:\n",
    "            break\n",
    "    return {'vipno':vipno,'root':troot}\n",
    "    \n",
    "\n",
    "def mergeNode(node1,node2,parent_node,tag='union'):\n",
    "    if node1.att_class == node2.att_class and \\\n",
    "        node1.att_level == node2.att_level:\n",
    "        if 'leaf' in [node1.node_type,node2.node_type]:\n",
    "            node_type = 'innode' if tag=='union' else 'leaf'\n",
    "        else:\n",
    "            node_type = 'innode'\n",
    "#             if node1.node_type!=node2.node_type:\n",
    "#                 raise Exception('error',node1.out(),node2.out())\n",
    "        return TreeNode(nodeType=node1.node_type,\n",
    "                        nodeClass=node1.att_class,\n",
    "                        level=node1.att_level,\n",
    "                        freq=sum([node1.att_freq,node2.att_freq]),\n",
    "                        tm=str(max(int(node1.att_tm),int(node2.att_tm))),\n",
    "                        parent=parent_node)\n",
    "    else:\n",
    "        raise Exception('error',node1.out(),node2.out())\n",
    "        return\n",
    "\n",
    "    \n",
    "def findNodeByClass(root,nodeClass,level=4):\n",
    "    res = [root]\n",
    "    ### get all node\n",
    "    for i in range(level):\n",
    "        temp = []\n",
    "        [temp.extend(x.att_childs) for x in res]\n",
    "        res.extend(temp)\n",
    "    res = list(filter(lambda x:x.att_class==nodeClass,res)) ### find the node\n",
    "    if len(res):\n",
    "        return res[0]\n",
    "    else:\n",
    "#         print('not found class',nodeClass)\n",
    "        raise Warning('not found class')\n",
    "        return None\n",
    "        \n",
    "        \n",
    "def unionTreeOfCusotomer(root1,root2,vipno=False):\n",
    "    res = {}\n",
    "    root = TreeNode(nodeType='root')\n",
    "    res['tree'] = root\n",
    "    \n",
    "    if vipno:\n",
    "        res['vipno'] = vipno\n",
    "    try:\n",
    "        current_level = []\n",
    "        [current_level.extend(x.att_childs) for x in [root1,root2]]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        root1.display()\n",
    "        root2.display()\n",
    "        raise e\n",
    "        \n",
    "    next_level = []\n",
    "    for i in range(1,5):\n",
    "        level = i\n",
    "        class_counter = Counter([x.att_class for x in current_level])\n",
    "        class_intersect = list(filter(lambda x:class_counter[x]>1,class_counter))\n",
    "        class_non_intersect = list(filter(lambda x:class_counter[x]==1,class_counter))\n",
    "        while len(current_level):\n",
    "            node = current_level.pop(0)\n",
    "            if node.att_class in class_intersect:\n",
    "                parent_node = findNodeByClass(root=root,nodeClass=node.att_parent.att_class,level=node.att_parent.att_level)\n",
    "                if parent_node is None:\n",
    "                    node.out()\n",
    "                    raise Exception('no parent')\n",
    "                node2 = list(filter(lambda x:x.att_class==node.att_class,current_level))[0]\n",
    "                current_level.remove(node2)\n",
    "                parent_node.att_childs.append(mergeNode(node,node2,parent_node))\n",
    "                next_level.extend(node.att_childs)\n",
    "                next_level.extend(node2.att_childs)\n",
    "            else:\n",
    "                parent_node = findNodeByClass(root=root,nodeClass=node.att_parent.att_class,level=node.att_parent.att_level)\n",
    "                parent_node.att_childs.append(node)\n",
    "                node.att_parent = parent_node\n",
    "        current_level = next_level\n",
    "        next_level = []\n",
    "         \n",
    "    return res\n",
    "\n",
    "\n",
    "def intersectTreeOfCusotomer(root1,root2,vipno=False):\n",
    "    res = {}\n",
    "    root = TreeNode(nodeType='root')\n",
    "    res['tree'] = root\n",
    "    \n",
    "    if vipno:\n",
    "        res['vipno'] = vipno\n",
    "    \n",
    "    current_level = []\n",
    "    [current_level.extend(x.att_childs) for x in [root1,root2]]\n",
    "    next_level = []\n",
    "    for i in range(1,5):\n",
    "        level = i\n",
    "        class_counter = Counter([x.att_class for x in current_level])\n",
    "        class_intersect = list(filter(lambda x:class_counter[x]>1,class_counter))\n",
    "        class_non_intersect = list(filter(lambda x:class_counter[x]==1,class_counter))\n",
    "        while len(current_level):\n",
    "            node = current_level.pop(0)\n",
    "            if node.att_class in class_intersect:\n",
    "                parent_node = findNodeByClass(root=root,nodeClass=node.att_parent.att_class,level=node.att_parent.att_level)\n",
    "                node2 = list(filter(lambda x:x.att_class==node.att_class,current_level))[0] ### get node to be merged\n",
    "                current_level.remove(node2)\n",
    "                parent_node.att_childs.append(mergeNode(node,node2,parent_node,tag='intersect')) ### add node\n",
    "                next_level.extend(node.att_childs)\n",
    "                next_level.extend(node2.att_childs)\n",
    "        current_level = next_level\n",
    "        next_level = []\n",
    "         \n",
    "    return res\n",
    "\n",
    "\n",
    "def buildTreeOfCustomers(df,all_customers):\n",
    "    global _col2\n",
    "    customer_forest = {c:TreeNode(nodeType='root') for c in all_customers}\n",
    "    for idx,row in df.iterrows():\n",
    "        cust = row[ _col2['vipno'] ]\n",
    "        subtree = createTreeBySingleTrans(row)['root']\n",
    "        customer_forest[cust] = unionTreeOfCusotomer(customer_forest[cust],subtree)['tree']\n",
    "    return customer_forest\n",
    "\n",
    "\n",
    "def sim_v_ur(v,ur):\n",
    "    try:\n",
    "        parentnode_ur = findNodeByClass(root=ur,nodeClass=v.att_parent.att_class)\n",
    "    except Warning as e:\n",
    "        return 0\n",
    "#     if parentnode_ur is None:\n",
    "#         return 0\n",
    "    freq_ur = [x.att_freq for x in parentnode_ur.att_childs]\n",
    "    try:\n",
    "        res = float(v.att_freq/np.sum(freq_ur))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "\n",
    "def sim_vl_ur(vl,ur):\n",
    "    if len(vl)==0:\n",
    "        return 0\n",
    "    try:\n",
    "        s = list(map(lambda x:sim_v_ur(x,ur),vl))\n",
    "        return np.mean(s)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "        \n",
    "def dist_ir_ur(ir,ur):\n",
    "    utree = unionTreeOfCusotomer(ir,ur)['tree']\n",
    "    itree = intersectTreeOfCusotomer(ir,ur)['tree']\n",
    "    ir = itree\n",
    "    ur = utree\n",
    "    nodes_ir = ir.get_all_nodes()\n",
    "    if len(nodes_ir)==0:\n",
    "        return 1\n",
    "    H = max(set(list(map(lambda x:x.att_level,nodes_ir))))\n",
    "    s = 0\n",
    "    for i in range(1,H+1):\n",
    "        w = i/np.sum(range(1,H+1))\n",
    "        vl = list(filter(lambda x:x.att_level==i,nodes_ir))\n",
    "        s += w*sim_vl_ur(vl,ur)\n",
    "    return 1-s\n",
    "\n",
    "def updateTreeByFrequence(root,freq):\n",
    "    current_level = [x for x in root.att_childs]\n",
    "    while len(current_level):\n",
    "        x = current_level.pop(0)\n",
    "        if x.att_freq>=freq:\n",
    "            current_level.extend(x.att_childs)\n",
    "        else:\n",
    "            try:\n",
    "                p = x.att_parent\n",
    "                p.att_childs.remove(x)\n",
    "\n",
    "#                 temp_node = p\n",
    "#                 while temp_node.node_type!='root':\n",
    "#                     temp_node.att_freq -= x.att_freq\n",
    "#                     temp_node = temp_node.att_parent\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return x\n",
    "\n",
    "    return root\n",
    "\n",
    "def getClusterCentroid(forest_customer):\n",
    "    global customers\n",
    "    centroid = TreeNode(nodeType='root')\n",
    "    for tr in forest_customer:\n",
    "        centroid = unionTreeOfCusotomer(centroid,forest_customer[tr])['tree']\n",
    "    \n",
    "    current_freq = 1\n",
    "    mindist = 1e10\n",
    "    freq_step = centroid.get_avg_freq()\n",
    "    freq_end = centroid.get_max_freq()\n",
    "    centroid_record = centroid\n",
    "    size_average = np.mean(list(map(lambda x:forest_customer[x].get_node_size(),forest_customer)))\n",
    "    print('average node',size_average)\n",
    "    \n",
    "    while current_freq<freq_end:\n",
    "        centroid = updateTreeByFrequence(centroid,current_freq)\n",
    "        dist = sum([dist_ir_ur(forest_customer[c],centroid) for c in forest_customer])\n",
    "        if dist<mindist:\n",
    "            mindist = dist\n",
    "            centroid_record = centroid\n",
    "        if centroid.get_node_size()<size_average:\n",
    "            break\n",
    "        current_freq += freq_step\n",
    "    return centroid_record\n",
    "\n",
    "    \n",
    "\n",
    "def clusterMain():\n",
    "    \n",
    "    ### get distant pair\n",
    "    def distantPair(topK_key,forest_concern):\n",
    "        max_dist = 0\n",
    "        max_pair = None\n",
    "        for i in topK_key:\n",
    "            for j in topK_key:\n",
    "                if j>i:\n",
    "                    dist = dist_ir_ur(forest_concern[i],forest_concern[j])\n",
    "                    if dist>max_dist:\n",
    "                        max_dist = dist\n",
    "                        max_pair = (i,j)\n",
    "        return [max_dist,max_pair]\n",
    "\n",
    "    ### recluster forest_concern\n",
    "    def recluster():\n",
    "        subcluster = [[],[]]\n",
    "        for c in forest_concern:\n",
    "            current_tree = forest_concern[c]\n",
    "            [dist1,dist2] = [\n",
    "                dist_ir_ur(current_tree,forest_concern[max_pair[0]]),\n",
    "                dist_ir_ur(current_tree,forest_concern[max_pair[1]])\n",
    "            ]\n",
    "            if dist1<dist2:\n",
    "                subcluster[0].append(c)\n",
    "            else:\n",
    "                subcluster[1].append(c)\n",
    "        return subcluster\n",
    "\n",
    "    ### precluster [] ; postcluster [[]]\n",
    "    def computeBIC(precluster,postcluster):\n",
    "\n",
    "        N = len(precluster)\n",
    "        D = sum([customer_buy_count[x] for x in precluster])\n",
    "        pre_coff_1 = (N-1)\n",
    "        pre_sigma_s = 1.0/pre_coff_1 * np.sum(np.power(list(dist_concern.values()),2))\n",
    "        pre_likelihood = -N/2*np.log(2*np.pi) - N*D/2*np.log(pre_sigma_s) - pre_coff_1/2\n",
    "        pre_bic = pre_likelihood - 1*(D+1)/2*np.log(1)\n",
    "\n",
    "        N_i = np.array([len(postcluster[0]), len(postcluster[1])])\n",
    "        D_i = np.array([\n",
    "            sum([customer_buy_count[x] for x in postcluster[0]]),\n",
    "            sum([customer_buy_count[x] for x in postcluster[1]])\n",
    "        ])\n",
    "        post_coff_1 = N_i - 2\n",
    "        post_sigma_s = 1.0/post_coff_1 * np.array([ \n",
    "            np.sum( np.power(list( dist_1.values() ),2) ), \n",
    "            np.sum( np.power(list( dist_2.values() ),2) )\n",
    "        ])\n",
    "        post_likelihood = N_i*np.log(N_i) - N_i*np.log(N) - N_i/2*np.log(2*np.pi) - N_i*D/2*np.log(post_sigma_s) - post_coff_1/2\n",
    "        post_likelihood = np.sum(post_likelihood)\n",
    "        post_bic = post_likelihood - 2*(D+1)/2*np.log(2)\n",
    "\n",
    "        print('bic ',pre_bic,post_bic)\n",
    "        return pre_bic,post_bic\n",
    "    \n",
    "    ### compute metrics and scores\n",
    "    def computeMetrics(cluster_final):\n",
    "        cluster_final = cluster_static\n",
    "        mapping = {x:i for i,x in enumerate(customers,0)}\n",
    "        d = np.array([[0.0 for i in range(len(customers))] for j in range(len(customers))])\n",
    "        for i,x in enumerate(customers,0):\n",
    "            for j,y in enumerate(customers,0):\n",
    "                if j>=i:\n",
    "                    d[ mapping[x] ][ mapping[y] ] = dist_ir_ur(forest_customer[x],forest_customer[y])\n",
    "                    d[ mapping[y] ][ mapping[x] ] = d[ mapping[x] ][ mapping[y] ]\n",
    "\n",
    "        sc = 0\n",
    "        B = np.array([0.0 for i in range(len(customers))])\n",
    "        A = np.array([0.0 for j in range(len(customers))])\n",
    "        cust_all = set(customers)\n",
    "        for cl in cluster_final:\n",
    "            cust_cl = set(cl)\n",
    "            for p in cl:\n",
    "                same = cust_cl - set([p])\n",
    "                other = cust_all - cust_cl - set([p])\n",
    "                A[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[s] ] for s in same])\n",
    "                B[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[o] ] for o in other])\n",
    "        sc = np.mean([(B[i]-A[i])/np.max([A[i],B[i]]) for i in range(len(customers))])\n",
    "        print('sc ',sc)\n",
    "\n",
    "        cp = np.mean([ \n",
    "            np.mean( list(map(lambda x:dist_ir_ur(forest_customer[x],centroid_final[i]),cl)) ) \n",
    "            for i,cl in enumerate(cluster_final,0) \n",
    "        ])\n",
    "        print('cp ',cp)\n",
    "\n",
    "        return sc,cp\n",
    "\n",
    "    top_ratio = 0.5\n",
    "    topK_max = 50\n",
    "    split_threshold = 20\n",
    "    global new_df\n",
    "    customer_buy_count = new_df.groupby(by=[_col2['vipno']]).count()['uid'].to_dict() ### { customer:buy_count }\n",
    "    customers = list( set(new_df[_col2['vipno']]) ) ### all customers : list\n",
    "    forest_customer = buildTreeOfCustomers(new_df,customers) ### customer tree {vipno:root}\n",
    "    cluster_dynamic = [[x for x in customers]]\n",
    "    cluster_static = []\n",
    "    centroid_final = []\n",
    "    while len(cluster_dynamic):\n",
    "        cluster_concern = cluster_dynamic.pop(0)\n",
    "        cluster_concern = set(cluster_concern)\n",
    "        forest_concern = list(filter(lambda x:x in cluster_concern,forest_customer))\n",
    "        forest_concern = { x:forest_customer[x] for x in forest_concern }\n",
    "        centroid_concern = getClusterCentroid(forest_concern) ### centoid tree of interest\n",
    "        dist_concern = { x:dist_ir_ur(forest_concern[x],centroid_concern) for x in forest_concern } ### dist of @forest_concern & @centroid_concern\n",
    "        topK = min( [ topK_max,max([2,top_ratio*len(forest_concern)]) ] )\n",
    "        topK = int(topK)\n",
    "        topK_key = sorted(dist_concern,key=lambda x:dist_concern[x],reverse=True)[:topK]\n",
    "        [max_dist,max_pair] = distantPair(topK_key,forest_concern) ### find most distant pair\n",
    "        subcluster = recluster()\n",
    "        subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "        subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "        centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "        centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "        dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "        dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "        [ pre_bic,post_bic ] = computeBIC(list(cluster_concern),subcluster)\n",
    "        if post_bic<pre_bic or (len(subforest_1)<split_threshold or len(subforest_2)<split_threshold):\n",
    "            cluster_static.append(list(cluster_concern))\n",
    "            centroid_final.append(centroid_concern)\n",
    "            print('settle ',len(cluster_concern))\n",
    "        else:\n",
    "            cluster_dynamic.extend(subcluster)\n",
    "            print('split ',len(subcluster[0]),len(subcluster[1]))\n",
    "    return cluster_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# del root1\n",
    "root1 = createTreeBySingleTrans(new_df.iloc[0])\n",
    "root2 = createTreeBySingleTrans(new_df.iloc[1])\n",
    "root3 = createTreeBySingleTrans(new_df.iloc[2])\n",
    "root12 = unionTreeOfCusotomer(root1['root'],root2['root'])['tree']\n",
    "# unionTreeOfCusotomer(root12,root3['root'])['tree'].display()\n",
    "intersectTreeOfCusotomer(root12,root12)['tree'].display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average node 55.483539094650205\n",
      "average node 52.7942238267148\n",
      "average node 59.047846889952154\n",
      "bic  5893241.126106286 6070024.388103115\n",
      "split  277 209\n",
      "average node 52.7942238267148\n",
      "average node 54.40952380952381\n",
      "average node 51.80813953488372\n",
      "bic  1939891.0873797485 2011069.533117923\n",
      "split  105 172\n",
      "average node 59.047846889952154\n",
      "average node 58.38505747126437\n",
      "average node 62.34285714285714\n",
      "bic  1161210.0586859067 1193439.483759727\n",
      "split  174 35\n",
      "average node 54.40952380952381\n",
      "average node 59.5\n",
      "average node 51.971830985915496\n",
      "bic  327136.74073899403 338751.0560665581\n",
      "split  34 71\n",
      "average node 51.80813953488372\n",
      "average node 60.1875\n",
      "average node 48.564516129032256\n",
      "bic  728468.194493893 758043.5849672941\n",
      "split  48 124\n",
      "average node 58.38505747126437\n",
      "average node 56.85227272727273\n",
      "average node 59.95348837209303\n",
      "bic  814990.4274023339 838142.2130305989\n",
      "split  88 86\n",
      "average node 62.34285714285714\n",
      "average node 58.1875\n",
      "average node 65.84210526315789\n",
      "bic  38716.98410254362 36643.01691005982\n",
      "settle  35\n",
      "average node 59.5\n",
      "average node 62.48148148148148\n",
      "average node 48.0\n",
      "bic  46188.15453115285 47739.695132742956\n",
      "settle  34\n",
      "average node 51.971830985915496\n",
      "average node 56.095238095238095\n",
      "average node 50.24\n",
      "bic  139806.59124615387 144327.24924635387\n",
      "split  21 50\n",
      "average node 60.1875\n",
      "average node 44.0\n",
      "average node 66.2\n",
      "bic  68711.7146499929 72205.33642604007\n",
      "settle  48\n",
      "average node 48.564516129032256\n",
      "average node 53.52173913043478\n",
      "average node 45.64102564102564\n",
      "bic  378118.61090318445 387539.70387805515\n",
      "split  46 78\n",
      "average node 56.85227272727273\n",
      "average node 60.85\n",
      "average node 16.875\n",
      "bic  201678.6875264688 216385.8839089245\n",
      "settle  88\n",
      "average node 59.95348837209303\n",
      "average node 50.791666666666664\n",
      "average node 63.5\n",
      "bic  224828.12726061256 235609.81860799177\n",
      "split  24 62\n",
      "average node 56.095238095238095\n",
      "average node 45.77777777777778\n",
      "average node 63.833333333333336\n",
      "bic  16279.455785195703 16038.134475683108\n",
      "settle  21\n",
      "average node 50.24\n",
      "average node 48.1\n",
      "average node 50.775\n",
      "bic  67151.86665019902 68345.07490038588\n",
      "settle  50\n",
      "average node 53.52173913043478\n",
      "average node 50.0\n",
      "average node 60.125\n",
      "bic  61537.8500409496 66793.4891397144\n",
      "split  30 16\n",
      "average node 45.64102564102564\n",
      "average node 42.96551724137931\n",
      "average node 47.224489795918366\n",
      "bic  144291.2911283973 151645.350109916\n",
      "split  29 49\n",
      "average node 50.791666666666664\n",
      "average node 36.0\n",
      "average node 53.75\n",
      "bic  20789.072190948416 20747.37312094351\n",
      "settle  24\n",
      "average node 63.5\n",
      "average node 62.77777777777778\n",
      "average node 65.41176470588235\n",
      "bic  121002.59297584087 127089.38264830962\n",
      "split  45 17\n",
      "average node 50.0\n",
      "average node 43.72727272727273\n",
      "average node 53.63157894736842\n",
      "bic  27916.754661327286 26120.04098183305\n",
      "settle  30\n",
      "average node 60.125\n",
      "average node 57.63636363636363\n",
      "average node 65.6\n",
      "bic  9715.120667007448 9136.483559741158\n",
      "settle  16\n",
      "average node 42.96551724137931\n",
      "average node 42.5\n",
      "average node 43.4\n",
      "bic  22928.58667752938 22696.337522665664\n",
      "settle  29\n",
      "average node 47.224489795918366\n",
      "average node 47.53658536585366\n",
      "average node 45.625\n",
      "bic  59564.93480622992 61148.8083829008\n",
      "settle  49\n",
      "average node 62.77777777777778\n",
      "average node 62.90909090909091\n",
      "average node 62.65217391304348\n",
      "bic  65558.27039696899 67344.46348761371\n",
      "split  22 23\n",
      "average node 65.41176470588235\n",
      "average node 73.42857142857143\n",
      "average node 59.8\n",
      "bic  11720.72505092019 11882.12987006999\n",
      "settle  17\n",
      "average node 62.90909090909091\n",
      "average node 49.0\n",
      "average node 68.125\n",
      "bic  18400.204172719594 16839.78878116149\n",
      "settle  22\n",
      "average node 62.65217391304348\n",
      "average node 65.5\n",
      "average node 61.64705882352941\n",
      "bic  17284.854638432804 15886.131401099148\n",
      "settle  23\n",
      "sc  0.08408521767308817\n",
      "cp  0.4901503310115557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08408521767308817, 0.4901503310115557)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get distant pair\n",
    "def distantPair(topK_key,forest_concern):\n",
    "    max_dist = 0\n",
    "    max_pair = None\n",
    "    for i in topK_key:\n",
    "        for j in topK_key:\n",
    "            if j>i:\n",
    "                dist = dist_ir_ur(forest_concern[i],forest_concern[j])\n",
    "                if dist>max_dist:\n",
    "                    max_dist = dist\n",
    "                    max_pair = (i,j)\n",
    "    return [max_dist,max_pair]\n",
    "\n",
    "### recluster forest_concern\n",
    "def recluster():\n",
    "    subcluster = [[],[]]\n",
    "    for c in forest_concern:\n",
    "        current_tree = forest_concern[c]\n",
    "        [dist1,dist2] = [\n",
    "            dist_ir_ur(current_tree,forest_concern[max_pair[0]]),\n",
    "            dist_ir_ur(current_tree,forest_concern[max_pair[1]])\n",
    "        ]\n",
    "        if dist1<dist2:\n",
    "            subcluster[0].append(c)\n",
    "        else:\n",
    "            subcluster[1].append(c)\n",
    "    return subcluster\n",
    "\n",
    "### precluster [] ; postcluster [[]]\n",
    "def computeBIC(precluster,postcluster):\n",
    "\n",
    "    N = len(precluster)\n",
    "    D = sum([customer_buy_count[x] for x in precluster])\n",
    "    pre_coff_1 = (N-1)\n",
    "    pre_sigma_s = 1.0/pre_coff_1 * np.sum(np.power(list(dist_concern.values()),2))\n",
    "    pre_likelihood = -N/2*np.log(2*np.pi) - N*D/2*np.log(pre_sigma_s) - pre_coff_1/2\n",
    "    pre_bic = pre_likelihood - 1*(D+1)/2*np.log(1)\n",
    "\n",
    "    N_i = np.array([len(postcluster[0]), len(postcluster[1])])\n",
    "    D_i = np.array([\n",
    "        sum([customer_buy_count[x] for x in postcluster[0]]),\n",
    "        sum([customer_buy_count[x] for x in postcluster[1]])\n",
    "    ])\n",
    "    post_coff_1 = N_i - 2\n",
    "    post_sigma_s = 1.0/post_coff_1 * np.array([ \n",
    "        np.sum( np.power(list( dist_1.values() ),2) ), \n",
    "        np.sum( np.power(list( dist_2.values() ),2) )\n",
    "    ])\n",
    "    post_likelihood = N_i*np.log(N_i) - N_i*np.log(N) - N_i/2*np.log(2*np.pi) - N_i*D/2*np.log(post_sigma_s) - post_coff_1/2\n",
    "    post_likelihood = np.sum(post_likelihood)\n",
    "    post_bic = post_likelihood - 2*(D+1)/2*np.log(2)\n",
    "\n",
    "    print('bic ',pre_bic,post_bic)\n",
    "    return pre_bic,post_bic\n",
    "\n",
    "### compute metrics and scores\n",
    "def computeMetrics(cluster_final):\n",
    "    cluster_final = cluster_static\n",
    "    mapping = {x:i for i,x in enumerate(customers,0)}\n",
    "    d = np.array([[0.0 for i in range(len(customers))] for j in range(len(customers))])\n",
    "    for i,x in enumerate(customers,0):\n",
    "        for j,y in enumerate(customers,0):\n",
    "            if j>=i:\n",
    "                d[ mapping[x] ][ mapping[y] ] = dist_ir_ur(forest_customer[x],forest_customer[y])\n",
    "                d[ mapping[y] ][ mapping[x] ] = d[ mapping[x] ][ mapping[y] ]\n",
    "\n",
    "    sc = 0\n",
    "    B = np.array([0.0 for i in range(len(customers))])\n",
    "    A = np.array([0.0 for j in range(len(customers))])\n",
    "    cust_all = set(customers)\n",
    "    for cl in cluster_final:\n",
    "        cust_cl = set(cl)\n",
    "        for p in cl:\n",
    "            same = cust_cl - set([p])\n",
    "            other = cust_all - cust_cl - set([p])\n",
    "            A[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[s] ] for s in same])\n",
    "            B[ mapping[p] ] = np.mean([d[ mapping[p] ][ mapping[o] ] for o in other])\n",
    "    sc = np.mean([(B[i]-A[i])/np.max([A[i],B[i]]) for i in range(len(customers))])\n",
    "    print('sc ',sc)\n",
    "\n",
    "    cp = np.mean([ \n",
    "        np.mean( list(map(lambda x:dist_ir_ur(forest_customer[x],centroid_final[i]),cl)) ) \n",
    "        for i,cl in enumerate(cluster_final,0) \n",
    "    ])\n",
    "    print('cp ',cp)\n",
    "\n",
    "    return sc,cp\n",
    "\n",
    "top_ratio = 0.5\n",
    "topK_max = 50\n",
    "split_threshold = 15\n",
    "global new_df\n",
    "customer_buy_count = new_df.groupby(by=[_col2['vipno']]).count()['uid'].to_dict() ### { customer:buy_count }\n",
    "customers = list( set(new_df[_col2['vipno']]) ) ### all customers : list\n",
    "forest_customer = buildTreeOfCustomers(new_df,customers) ### customer tree {vipno:root}\n",
    "cluster_dynamic = [[x for x in customers]]\n",
    "cluster_static = []\n",
    "centroid_final = []\n",
    "while len(cluster_dynamic):\n",
    "    cluster_concern = cluster_dynamic.pop(0)\n",
    "    cluster_concern = set(cluster_concern)\n",
    "    forest_concern = list(filter(lambda x:x in cluster_concern,forest_customer))\n",
    "    forest_concern = { x:forest_customer[x] for x in forest_concern }\n",
    "    centroid_concern = getClusterCentroid(forest_concern) ### centoid tree of interest\n",
    "    dist_concern = { x:dist_ir_ur(forest_concern[x],centroid_concern) for x in forest_concern } ### dist of @forest_concern & @centroid_concern\n",
    "    topK = min( [ topK_max,max([2,top_ratio*len(forest_concern)]) ] )\n",
    "    topK = int(topK)\n",
    "    topK_key = sorted(dist_concern,key=lambda x:dist_concern[x],reverse=True)[:topK]\n",
    "    [max_dist,max_pair] = distantPair(topK_key,forest_concern) ### find most distant pair\n",
    "    subcluster = recluster()\n",
    "    subforest_1 = { x:forest_customer[x] for x in subcluster[0] }\n",
    "    subforest_2 = { x:forest_customer[x] for x in subcluster[1] }\n",
    "    centroid_1 = getClusterCentroid(subforest_1) ### costing\n",
    "    centroid_2 = getClusterCentroid(subforest_2) ### costing\n",
    "    dist_1 = { x:dist_ir_ur(subforest_1[x],centroid_1) for x in subcluster[0] } ### costing\n",
    "    dist_2 = { x:dist_ir_ur(subforest_2[x],centroid_2) for x in subcluster[1] } ### costing\n",
    "    [ pre_bic,post_bic ] = computeBIC(list(cluster_concern),subcluster)\n",
    "    if post_bic<pre_bic or (len(subforest_1)<split_threshold or len(subforest_2)<split_threshold):\n",
    "        cluster_static.append(list(cluster_concern))\n",
    "        centroid_final.append(centroid_concern)\n",
    "        print('settle ',len(cluster_concern))\n",
    "    else:\n",
    "        cluster_dynamic.extend(subcluster)\n",
    "        print('split ',len(subcluster[0]),len(subcluster[1]))\n",
    "computeMetrics(cluster_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_customer[1591015476700].display()\n",
    "computeMetrics(cluster_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### test case 1\n",
    "r1 = TreeNode(nodeType='root')\n",
    "r11=TreeNode(nodeType='innode',nodeClass='Food',freq=2,level=1,parent=r1)\n",
    "r1.att_childs.append(r11)\n",
    "r12=TreeNode(nodeType='innode',nodeClass='Clothes',freq=1,level=1,parent=r1)\n",
    "r1.att_childs.append(r12)\n",
    "\n",
    "r21=TreeNode(nodeType='innode',nodeClass='Drink',freq=2,level=2,parent=r11)\n",
    "r11.att_childs.append(r21)\n",
    "r22=TreeNode(nodeType='innode',nodeClass='Children Clothes',freq=1,level=2,parent=r12)\n",
    "r12.att_childs.append(r22)\n",
    "\n",
    "r31=TreeNode(nodeType='innode',nodeClass='Tea',freq=2,level=3,parent=r21)\n",
    "r21.att_childs.append(r31)\n",
    "\n",
    "r41=TreeNode(nodeType='innode',nodeClass='Black Tea',freq=1,level=4,parent=r31)\n",
    "r31.att_childs.append(r41)\n",
    "r42=TreeNode(nodeType='innode',nodeClass='Green Tea',freq=1,level=4,parent=r31)\n",
    "r31.att_childs.append(r42)\n",
    "\n",
    "\n",
    "\n",
    "t1 = TreeNode(nodeType='root')\n",
    "t11=TreeNode(nodeType='innode',nodeClass='Food',freq=2,level=1,parent=t1)\n",
    "t1.att_childs.append(t11)\n",
    "t12=TreeNode(nodeType='innode',nodeClass='Electronics',freq=1,level=1,parent=t1)\n",
    "t1.att_childs.append(t12)\n",
    "\n",
    "t21=TreeNode(nodeType='innode',nodeClass='Drink',freq=2,level=2,parent=t11)\n",
    "t11.att_childs.append(t21)\n",
    "\n",
    "t31=TreeNode(nodeType='innode',nodeClass='Tea',freq=1,level=3,parent=t21)\n",
    "t21.att_childs.append(t31)\n",
    "t32=TreeNode(nodeType='innode',nodeClass='Juice',freq=1,level=3,parent=t21)\n",
    "t21.att_childs.append(t32)\n",
    "\n",
    "t41=TreeNode(nodeType='innode',nodeClass='Black Tea',freq=1,level=4,parent=r31)\n",
    "t31.att_childs.append(t41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2416666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = unionTreeOfCusotomer(r1,t1)['tree']\n",
    "print()\n",
    "b = intersectTreeOfCusotomer(r1,t1)['tree']\n",
    "dist_ir_ur(r1,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodetype': 'root', 'att_childs': 1, 'att_freq': 0, 'att_class': '', 'att_level': 0, 'att_tm': 0, 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '15', 'att_level': 1, 'att_tm': '20160730', 'parent': ''}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '151', 'att_level': 2, 'att_tm': '20160730', 'parent': '15'}\n",
      "{'nodetype': 'innode', 'att_childs': 1, 'att_freq': 1, 'att_class': '1512', 'att_level': 3, 'att_tm': '20160730', 'parent': '151'}\n",
      "{'nodetype': 'leaf', 'att_childs': 0, 'att_freq': 1, 'att_class': '15120', 'att_level': 4, 'att_tm': '20160730', 'parent': '1512'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sldatime</th>\n",
       "      <th>cmrid</th>\n",
       "      <th>vipno</th>\n",
       "      <th>pluno</th>\n",
       "      <th>amt</th>\n",
       "      <th>qty</th>\n",
       "      <th>bndno</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>tran_time_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16691</th>\n",
       "      <td>16073014031928627</td>\n",
       "      <td>1.469859e+09</td>\n",
       "      <td>女[18 - 25]</td>\n",
       "      <td>781924</td>\n",
       "      <td>15120000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15012.0</td>\n",
       "      <td>15</td>\n",
       "      <td>151</td>\n",
       "      <td>1512</td>\n",
       "      <td>15120</td>\n",
       "      <td>000</td>\n",
       "      <td>20160730</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid      sldatime       cmrid   vipno     pluno   amt  \\\n",
       "16691  16073014031928627  1.469859e+09  女[18 - 25]  781924  15120000  15.0   \n",
       "\n",
       "       qty    bndno class1 class2 class3 class4 class5 tran_date  \\\n",
       "16691  6.0  15012.0     15    151   1512  15120    000  20160730   \n",
       "\n",
       "       tran_time_level  \n",
       "16691                4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = new_df.iloc[0]\n",
    "createTreeBySingleTrans(item)['root'].display()\n",
    "new_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list(dist_concern.values())\n",
    "r = sorted(r)\n",
    "sns.distplot(r,bins=200)\n",
    "r1 = list(dist_1.values())\n",
    "r1 = sorted(r1)\n",
    "r2 = list(dist_2.values())\n",
    "r2 = sorted(r2)\n",
    "sns.distplot(r1,bins=100)\n",
    "sns.distplot(r2,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*[1,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
